{"pages":[{"title":"","text":"naver-site-verification: naver7f8bedb045f6d9075271fccc4ee26fa8.html","link":"/naver7f8bedb045f6d9075271fccc4ee26fa8.html"}],"posts":[{"title":"About Redis","text":"RedisREDIS 개요REDIS란?REmote DIctionary Server, 디스크 기반이 아닌 인메모리 기반 데이터 저장소이다. 메모리를 사용하기 때문에 매우 빠른 장점이 있으며, 고가용성 및 샤딩을 통한 파티셔닝을 지원한다. 하지만 단점으로는 메모리 크기에 한정적이다. 아직까지는 동일 용량의 디스크 대비 메모리 가격이 비싸다. 그래서 사용하는 메모리 용량에 따라 경제적 부담을 져야하는 기회비용에 직면하게 된다. 또한 레디스는 키벨류 베이스의 디비로써, 복잡한 연산의 데이터베이스 방식에는 적절하지 않으나?! 아래 소개하는 spring data redis 로 구현은?! 할수 있다. 하지만, 여기에도 장단이 존재한다.. 관련해서 아래에서 알아보자. 리스트 데이터 입력 삭제가 MYSQL 대비 10배 빠르다고함! MAX 100,000 QPS Redis서버는 1개의 싱글 쓰레드로 수행, 따라서 하나의 서버에 여러개의 서버 띄우는게 가능, 또한 이러한 특성으로 다양한 이슈가 만들어 질수 있음 REDIS vs MEMCACHED 둘다 속도는 100000QPS 로 비슷 둘다 샤딩을 통한 클러스터링 모드 지원 자료구조는 레디스가 많이 지원, 멤케시는 key-value만 지원 안정성의경우, 멤케시는 장애가 거의 없으나, 레디스의 경우 특성을 잘못 이해할경우 프로세스 장애 발생. flush_all 같은경우 응답속도의 균일성의 경우, 멤케시는 전체적으로 균일하나, 레디스는 멤케시에 비해 균일성이 떨어 질수 있음, 롱쿼리.. 장애대응 혹은 영속성의경우, 레디스는 RDB(Snapshot)와 AOF(Journal)지원, 하지만 맴케시는 프로세스 재시작시 데이터 모두 날라감. 멤캐시 철학은 약간 “캐시는 정말 캐시 용도로만 써야되고, 데이터 초기화시 다시 원천소스를 조회하여 캐싱해야한다.” 와 같음 멤케시의 경우 ‘라이브러리로’ master/master 리플리케이션만 지원, 하지만 레디스는 ‘자체기능’으로 (master/slave)리플리케이션만 지원 REDIS DATA TYPE아래에서 설명하는 데이터타입의경우, 실제 key-value 에서 value에 저장되는 데이터 타입을 말한다. 이것을 반드시 인지하고있어야한다. String 동작 및 특징 가장 기본이 되는 타입 용도 HTML 페이지, API 응답 이미지, 비디오, 텍스트, 바이너리 데이터 등 캐시 개수 계산이 필요한 페이지뷰, 비디오뷰 좋아요 같은 서비스 Hash 동작 및 특징 키값에 해당되는 필드를 선택적으로 가져올수 잇다. 객체를 저장하는데 훌륭 용도 특정 Key 값에 여러 field(hashKey)가 존재하여, 다양한 케이스에서 선택적으로 value를 가져와야하는경우 List 동작 및 특징 collection, stack, queue와 같이 동작 할수 있음 용도 이벤트큐, 최근 사용자 글 저장하기등 Set 동작 및 특징 순서없고, 동일한 값이 없는 콜렉션 특성을 가지고 있다. (추가,삭제,검색 성능 속도 O(1)) 내부는 hash table 로 구현되있다. 교집합, 합집합 빠르게 계산 용도 데이터 필터링 : 특정도시에서 출발해서 특정도시로 도착하는 모든 비행기 필터링? 데이터 그룹핑 : 비슷한 제품을 보는 모든 사용자 그룹핑 엘리먼트십 확인 : 블랙리스트확인 혹은 사용자가 이미 푸시를 받앗는지 확인하기(dup check) Sorted Set 동작 및 특징 용도 BitMap 동작 및 특징 특정 인덱스에 값을 0 또는 1로 set 및 get이 가능하다. 단일 저장 용량이 1Bit 라서, 메모리를 아주 적게 사용하여 스냅샷 서비스를 제공할수 있다. 용도 오늘 방문한 순수 사용자, 혹은 카운트 특정 모바일 아이디에 중복 발송을 필터링하기위한 테이블 HyperLogLog 동작 및 특징 용도 REDIS PERSISTENCE 시스템의 영속성을 보장하기위해 레디스에선 데이터를 디스크에 백업해 놓는 2가지 방식을 제공하고 있다. Snapshotting : 레디스에 저장된 데이터를 바이너리 스냅샷으로 생성(메모리 덤프) > RDB 모드 fork 로 자식 프로세스 생성하여 저장하는 방식 쓰기 작업이 많아지면 부모와 자식 둘다 같은 크기의 메모리를 사용할수 있음. 메모리 부족 이슈 가능 설정파일에 save 900 1 , save 300 60, save 60 10000 과 같이 설정 Journaling : 시간이 지나면서 요청된 커맨드를 사람이 읽을수 있는 파일로 생성 > AOF 모드 만약 재기동 시점에 둘다 있으면, AOF 가 가장 마지막까지 실행됫다고 가정하고, AOF 모드로 재실행 하지만 이러한 persistence 기능이 장애의 주된 원인이 될수있어서, 아주 잘 사용해야 한다. KEY EXPIREATION, TRANSACTION, PUB/SUBKEY EXPIREATIONkey 값에 expireTime 지정이 가능하며, 해당 만료 시간을 기준으로 데이터가 삭제된다. 2가지 방식이 있으며, 초단위로 설정하거나 종료시점 날짜를 설정하여 만료시킬수 있음 맴케시의경우, 사용자가 get할때 expire체크를 하여 만료작업을 처리하지만, 레디스는 이 방법과 더불어 내부적으로 cron()을 돌려 추가적으로 만료작업을 진행한다. TRANSACTIONPUB/SUBREDIS CLUSTER레디스 시스템 성능 확장을 위해 클러스터 모드로 레디스를 실행할수 있다. 노드간에 처리 대상은 수평분할(샤딩)의 한 방식인 해시분할(Hash partitioning)에 의해서 결정된다 해시분할방식은, 해시함수에 키값을 넣어 정수값(0~16383)을 추출, 각 마스터 노드 해시슬롯 범위에 포함된 곳에서 처리되도록 한다. 이러한 Hash key slot을 사용하여 샤딩방식으로 트래픽을 클러스터 노드별로 분산한다. REDIS REPLICATION 혹시모를 장애로 마스터 서버 이슈로, 데이터 유실 혹은 read 트래픽 분산을 위해 레디스 또한 데이터 리플리케이션 기능을 제공한다. master / slave 복제 방식이다 REDIS HA(High Avaliability) 기본적으론 레디스 센티널 HA 컨트롤 되긴함. m/s 복제 되어잇어야함 redis2.6부터 slave-read-only가 yes로 되어 있어, 무조건 마스터승격 시에 쓰기 요청 모두 실패됨. 추가설정필요.. 하지만, 아주 다행히 AWS Elastic cache:Redis 사용시 replication, multi-az 2개 설정만으로 자동 장애복구 지원됨. replica 만 선택하고, multi-az 설정안하면, 사용자가 직접 마스터 승격시켜줘야하니.. multi-az 설정까지 해주자.ㅎㅎ 참고 : https://aws.amazon.com/ko/elasticache/faqs#다중_AZ REDIS 적용‘’터미널’’에서 REDIS (클러스터) 로컬환경 구축 및 사용12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# redis가 로컬에 설치 되엇다는 가정하에 아래 실습을 진행할수 있다. # 6379 포트로 redis를 띄운다.$ redis-server127.0.0.1:6379> {{redis command}}# redis-cli는 레디스에 커맨드를 실행할수 있게 해준다. # 아래는 해당 노드에 저장된 값의 size를 알수있는 command$ redis-cli -h 127.0.0.1 -p 5000### 실제 로컬에서 띄울때 클러스터 모드로 띄워도 될듯!! 아래는 그 방법###$ redis-server --port 5000 --cluster-enabled yes --cluster-config-file nodes-5000.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor 10 --cluster-migration-barrier 1 --cluster-require-full-coverage yes --dbfilename dump-5000.rdb --daemonize yes$ redis-server --port 5001 --cluster-enabled yes --cluster-config-file nodes-5001.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor 10 --cluster-migration-barrier 1 --cluster-require-full-coverage yes --dbfilename dump-5001.rdb --daemonize yes$ redis-server --port 5002 --cluster-enabled yes --cluster-config-file nodes-5002.conf --cluster-node-timeout 2000 --cluster-slave-validity-factor 10 --cluster-migration-barrier 1 --cluster-require-full-coverage yes --dbfilename dump-5002.rdb --daemonize yes$ redis-cli -c -p 5000 cluster addslots {0..5460}$ redis-cli -c -p 5001 cluster addslots {5461..10922}$ redis-cli -c -p 5002 cluster addslots {10923..16383}$ redis-cli -c -p 5000 cluster set-config-epoch 1$ redis-cli -c -p 5001 cluster set-config-epoch 2$ redis-cli -c -p 5002 cluster set-config-epoch 3$ redis-cli -c -p 5000 cluster meet 127.0.0.1 5001$ redis-cli -c -p 5000 cluster meet 127.0.0.1 5002$ redis-cli -c -p 6000 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6001 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6002 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6003 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6004 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6005 cluster meet 127.0.0.1 5000$ redis-cli -c -p 6000 cluster replicate {{masterNodeIdForReplica}}$ redis-cli -c -p 6001 cluster replicate {{masterNodeIdForReplica}}$ redis-cli -c -p 6002 cluster replicate {{masterNodeIdForReplica}}$ redis-cli -c -p 6003 cluster replicate {{masterNodeIdForReplica}}$ redis-cli -c -p 6004 cluster replicate {{masterNodeIdForReplica}}$ redis-cli -c -p 6005 cluster replicate {{masterNodeIdForReplica}}# 클러스터 모드에서 사용$ redis-cli -h 127.0.0.1 -p 5000 -c127.0.0.1:5000> set hello worldOK127.0.0.1:5000> get hello\"world\"127.0.0.1:5000> set hello2 world2-> Redirected to slot [7486] located at 127.0.0.1:5001OK127.0.0.1:5001> get hello2\"world2\" REDIS Client Library(각 라이브러리 장단점)java base의 redis client libracy 중에 recommed 하는 라이브러리는 크게 3가지 Jedis, Lettuce, Redisson가 있다. Jedis small Lettuce thread-safe sync async REDISON 비동기 하이퍼포먼스 lock free redis client AWS REDIS 소개AWS 의 서비스중에 ElasticCache 라는 것이 있는데, 해당 서비스는 인메모리 서비스 그룹으로, 실제로 해당 서비스 실행을 위해 Redis를 쓸지 Memchaed를 쓸지 선택할수 있다. AWS의 인프라 제공 능력?!으로 클릭 몇번으로 클러스터기반 마스터슬래이브 레디스 서비스를 실행할수 있다. (자동 장애복구 기능도 지원한당. 짜응) 기타 알면 좋은것들SPRINT DATA REDIS (Spring data redis + lettuce)Sample1234567891011121314151617181920212223242526272829303132333435363738// entity class@Getter@Builder@AllArgsConstructor(access = AccessLevel.PRIVATE)@NoArgsConstructor@ToString@RedisHash(\"pushResult\")public class PushResult { @Id private Long id; @Indexed private long mobileSeq; @Indexed private long campaignId; private long offerId; @Indexed private LocalDateTime preferredAt;}// *RedisRepository interfacepublic interface PushResultRepository extends CrudRepository { PushResult findByMobileSeqAndCampaignId(Long mobileSeq, Long cId);}// service class@Servicepublic PushResultService { @Autowired private PushResultRepository pushResultRepository; public void add(PushResult pushResult) { pushResultRepository.save(pushResult); } public PushResult getByMobileSeqAndCId(Long mobileSeq, Long cId) { return pushResultRepository.findByMobileSeqAndCampaignId(mobileSeq, cId); }} 동작12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182################################################################ 위 spring data jpa 를 사용하여 1건의 pushResult 를 save 할경우 ################################################################# redis cluster nodes 에 저장된 key 개수 $ redis-cli -h 127.0.0.1 -p 5000 dbsize(integer) 2$ redis-cli -h 127.0.0.1 -p 5001 dbsize(integer) 1$ redis-cli -h 127.0.0.1 -p 5002 dbsize(integer) 3# redis cluster nodes 에 저장된 key 종류$ 127.0.0.1:5000> keys *1) \"pushResult:campaignId:223456\"2) \"pushResult:-7496779863478802681:idx\"$ 127.0.0.1:5001> keys *1) \"pushResult:preferredAt:2018-10-16T15:49:12.949\"$127.0.0.1:5002> keys *1) \"pushResult:mobileSeq:123456\"2) \"pushResult:-7496779863478802681\"3) \"pushResult\"# 각 key 에 대한 value$ 127.0.0.1:5000> smembers pushResult:campaignId:2234561) \"-7496779863478802681\"$ 127.0.0.1:5000> smembers pushResult:-7496779863478802681:idx1) \"pushResult:mobileSeq:123456\"2) \"pushResult:campaignId:223456\"3) \"pushResult:preferredAt:2018-10-16T15:49:12.949\"$ 127.0.0.1:5001> smembers pushResult:preferredAt:2018-10-16T15:49:12.9491) \"-7496779863478802681\"$ 127.0.0.1:5002> smembers pushResult:mobileSeq:1234561) \"-7496779863478802681\"$ 127.0.0.1:5002> smembers pushResult1) \"-7496779863478802681\"$ 127.0.0.1:5002> hkeys pushResult:-74967798634788026811) \"_class\"2) \"mobileSeq\"3) \"id\"4) \"mobileSeq._class\"5) \"offerId\"6) \"offerId._class\"7) \"campaignId\"8) \"campaignId._class\"9) \"preferredAt\"$ 127.0.0.1:5002> hgetall pushResult:-7496779863478802681 1) \"mobileSeq._class\" 2) \"java.lang.Long\" 3) \"offerId\" 4) \"123456\" 5) \"offerId._class\" 6) \"java.lang.Long\" 7) \"campaignId\" 8) \"223456\" 9) \"campaignId._class\"10) \"java.lang.Long\"11) \"mobileSeq\"12) \"123456\"13) \"_class\"14) \"com.~.pushcontroller.domain.result.PushResult\"15) \"id\"16) \"-7496779863478802681\"17) \"preferredAt\"18) \"2018-10-16T15:49:12.949\"############################## 위 명령어가 다른이유 ############################### if value is of type string -> GET # if value is of type hash -> HGETALL # if value is of type lists -> lrange # if value is of type sets -> smembers # if value is of type sorted sets -> ZRANGEBYSCORE ############################################################################# REDIS 비교 결과1234567############################### [Local 환경]퍼포먼스 테스트 결과 ################################ master 3, slave6, network high# Redisson (pure redis client): 10000/sec# spring data redis : 33.3/sec CommandsCLUSTER INFO123456789101112131415161718192021222324252627282930# cluster meet 전cluster_state:failcluster_slots_assigned:0cluster_slots_ok:0cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:1cluster_size:0cluster_current_epoch:0cluster_my_epoch:0cluster_stats_messages_sent:0cluster_stats_messages_received:0# cluster meet 후cluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:3cluster_size:3cluster_current_epoch:3cluster_my_epoch:1cluster_stats_messages_ping_sent:553cluster_stats_messages_pong_sent:553cluster_stats_messages_meet_sent:2cluster_stats_messages_sent:1108cluster_stats_messages_ping_received:553cluster_stats_messages_pong_received:555cluster_stats_messages_received:1108 CLUSTER KEYSLOT 12$ 127.0.0.1:5000> cluster keyslot pushResult:campaignId:225763(integer) 11216 CLIENT LIST123$ 127.0.0.1:5000> client listid=320 addr=127.0.0.1:49228 fd=320 name= age=1890 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=clientid=16 addr=127.0.0.1:63855 fd=16 name= age=2452 idle=2416 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=cluster # redis-trib.rb 사용하기123456789101112131415161718192021222324252627282930313233343536373839404142# redis cluster info< HEAD:_drafts/about-redis.md> 8199a64e366805ddde1586b4cf8444993e165799:_posts/2018-11-11-about-redis.md$./redis-trib.rb info 127.0.0.1:5000127.0.0.1:5000 (8b4b5f3a...) -> 2 keys | 5461 slots | 0 slaves.127.0.0.1:5001 (9865af8c...) -> 0 keys | 5462 slots | 0 slaves.127.0.0.1:5002 (21ca40a9...) -> 4 keys | 5461 slots | 0 slaves.[OK] 6 keys in 3 masters.0.00 keys per slot on average.# check$./redis-trib.rb check 127.0.0.1:5000>>> Performing Cluster Check (using node 127.0.0.1:5000)M: 8b4b5f3aa0357331c644f2cf678a3b5eb7b42aa6 127.0.0.1:5000 slots:0-5460 (5461 slots) master 0 additional replica(s)M: 9865af8cda8dca53a8e5776900961540566af4aa 127.0.0.1:5001 slots:5461-10922 (5462 slots) master 0 additional replica(s)M: 21ca40a9a2c8e178943d0b5311dbc4308ddd8438 127.0.0.1:5002 slots:10923-16383 (5461 slots) master 0 additional replica(s)[OK] All nodes agree about slots configuration.>>> Check for open slots...>>> Check slots coverage...[OK] All 16384 slots covered.# call ex1$./redis-trib.rb call 127.0.0.1:5000 dbsize>>> Calling DBSIZE127.0.0.1:5000: 2127.0.0.1:5001: 0127.0.0.1:5002: 4# call ex2$./redis-trib.rb call 127.0.0.1:5000 keys '*'>>> Calling KEYS *127.0.0.1:5000: [\"pushResult:preferredAt:2018-10-16T16:54:38.601\", \"pushResult:campaignId:223456\"]127.0.0.1:5001: []127.0.0.1:5002: [\"pushResult:mobileSeq:123456\", \"pushResult:-1799219234927987399:idx\", \"pushResult:-1799219234927987399\", \"pushResult\"] 123456789# 35개의 pushResult에 대해서 176개의 key 가 생성 되었고, 소요시간은 10초...$ ./redis-trib.rb info endpoint.clustercfg.apn2.cache.amazonaws.com:637910.213.145.56:6379 (38a8538d...) -> 65 keys | 5461 slots | 2 slaves.10.213.145.43:6379 (84128d7b...) -> 62 keys | 5461 slots | 2 slaves.10.213.145.50:6379 (6fdadcab...) -> 49 keys | 5462 slots | 2 slaves.[OK] 176 keys in 3 masters.0.01 keys per slot on average.# (dev) 1224 개의 데이터를 bucket key/value 형태로 저장한결과 102/sec 참고서적 Memcached 와 Redis Redis 운영관리 Redis 핵심정리 참고사이트 출처 : https://redis.io/clients#java 출처 : http://bcho.tistory.com/654 출처 : http://bcho.tistory.com/tag/%EA%B0%95%EB%8C%80%EB%AA%85 출처 : https://redis.io/ 출처 : https://aws.amazon.com/ko/elasticache/redis/","link":"/2018/11/12/about-redis/"},{"title":"OOP : Object Oriented Programming","text":"객체지향의 사실과 오해 : 역할, 책임, 협력관점에서 본 객체지향 객체지향의 공통적인 특징 : 추상화, 캡슐화, 상속, 다형성 객체지향 디자인의 5원칙(SOLID 원칙) S - SRP (Single Responsibility Principle) O - OCP (Open Closed Principle) L - LSP (Liskov Substitusion Principle) I - ISP (Interface Segregation Principle) D - DIP (Dependency Inversion Principle) 객체지향이란 무엇인가? 클래스가 아닌, 객체를 바라보는것 기능을 구현하기 위해 협력하는 공동체의 존재 협력에 참여하는 객체들에게 얼마나 적절한 역할과 책임을 부여하는것 책의 구성 객체지향 패러다임의 핵심이 클래스나 상속이 아닌 자율적 객체의 협력 객체간에 req,resp를 통해 collaboration 할 수 있다. collaboration 과정속에 각 객체는 role을 부여받는다. 이러한 role은 협력안에서 차지하는 책임이나 임무를 의미 위에서 말한 객체에 대해 얘기, 객체는 상태와 행동, 식별자를 가진존재 타입과 추상화에 대해서 얘기. 동적인 객체들을 단순화시켜 정적인 타입으로 갈무리 하는것 객체지향의 핵심인 “역할, 책임, 협력“을 얘기 객체의 자율성과 설계의 유연성은 얼마나 훌륭한 “메시지“를 선택하느냐에 달려있다. 구조와 기능이라는 두가지 관점. 도메인 모델과 유스케이스 모델 결론 기타 객체란 현실세계에 존재하는 사물이나 현상, 정의에 대한 추상화 객체지향의 목표는 실세계를 모방하는것이 아닌 새로운 세계를 창조하는 것이다. 추가 RUP란?","link":"/2019/11/28/oop/"},{"title":"Unix & Linux command and shell script!","text":"Concept12345671. 0(stdin), 1(stdout), 2(stderr)2. input redirection(0< 생략), output redirection(1> 생략)3. > (replace), >> (없으면생성, 있으면 다음행에 append)4. >& (해당 기호 뒤에 fd 생략 불가능.. ex. >>&1 , >&2 )5. 명령어의 실행결과를 다음 명령어의 입력으로 연결하는, 즉 출입력을 연결하는 기호 1. ls -l /var/log | sort -rk 9 (9번째 열의 데이터로 desc)6. SomeCommand > /dev/null 2>&1 하면 로그 버림 Commands123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216# 사용가능한 모든 쉘$ cat /etc/shells# 현재 사용중인 쉘$ echo $SHELL# 쉘 바꾸기$ chsh$ date$ at (특정시간에 특정 잡을 실행)$ chmod (접근 권한 변경), ls -al 으로 확인(소유자,소유자그룹,모든사용자)# chmod 755 file# chmod u+x file$ chown (소유자, 소유자그룹변경. root 만 가능)$ cmp (파일을 비교하여 차이점을 알려주는 명령어)$ col (개행 혹은 공백 치환 역할을 하는 명령어)$ colctr (- 옵션과 같이 쓰면 '_' 를 제거해 준다.)$ cp (복사)(-r 디렉터리의 하위 파일 및 디렉토리 모두 복사)$ cut (파이프 결과중에 지정된 부분만 표시.)# (bcf 옵션에는 숫자범위 지정할수 있음. A, A-, A-B, -B)# (-c 문자단위로분할)# (-d 구분자이용)# (-f 지정된 필드만 표시)# (-s 구분자에 포함되지 않은 행은 표시하지 않음)# cut -d \":\" -f1,7 /etc/passwd 혹은 cut -d: -f1,2,3 /etc/passwd$ date (날짜 표시)# date +%Y-%m-%d' '%k:%M:%S# date +%Y%m%d%k%M%S$ df (파일 시스템의 디스크 용량 확인)# df -aH$ diff (두 파일간의 비교)$ du (현재 디렉터리의 사용량을 표시) # du -sh$ echo (문자열 출력, 환경변수 확인할수도 있음, 로그 용도로도 사용)$ find (파일을 찾을때 사용)$ free (메모리 사용량 체크 명령어)$ ifconfig (네트워크 인터페이스 설정 확인 및 변경)$ grep (대소문자 구별하여 검색) # (-c 해당 패턴 포함된 행의 개수 출력)# (-i 대소문자 구분없앰)# (-n 행번호 출력)# (-v 제외하고 출력)# 정규 표현식 가능. # cat somefile.txt | grep '[0-9]' // 숫자 포함 검색# la -al | grep '^d' | grep -v '[.]' // 현재 디렉토리에 파일 검색# ls -al | grep '\\.log$' // 로그 파일 검색# OR 조건 걸기. cat some.txt | grep 'A\\|B\\|C'$ lsof (list open files 명령어는 시스템에서 열린 파일 목록 확인 및 프로세스, 디바이스 정보 등을 표시)# (-i 특정 포트를 사용하는 프로세스를 출력. lsof -i TCP:80, lsof -i :22-2202)# (-c 특정 명령어가 사용하는 프로세스 출력. lsof -c httpd)# (+D 특정 디렉터리 하위에 열려있는 프로세스 출력. lsof +D ~)# lsof /var/log/messages 는 해당 파일을 사용하는 프로세스를 출력한다.$ netstat (현재 시스템에 연결되어 있는 네트워크 연결 상태 및 포트 정보 표시)# netstat -nr IP주소와 커널의 라우팅 테이블 정보를 출력. route와 동일$ ps (현재시스템의 프로세스 상태 출력)# ps -u crayon -ax$ script (터미널에서 수행하는 작업들을 텍스트 형식으로 저장한다.)$ sort (텍스트 파일을 행 단위로 정렬한다.)# (-d 알파벳과 숫자를 사전순으로 정렬한다.)# (-r desc 으로 정렬한다.)# (-t 필드 구분자를 지정한다.)# (-k 각 행의 지정된 필드를 기준으로 정렬한다.)# ls -alh | sort -rk 5 // 디렉토리에서 5행(용량) 기준으로 desc 정렬한다.# ls -alh | grep -v ^d | sort -rk 8$ tail (마지막 행의 내용부터 출력한다.)# (-f 명령을 종료하지 않고 추가되는 내용을 실시간으로 출력한다.)# (-n 마지막 행부터 n행까지의 내용을 출력한다. n 생략 가능.. tail -10 somefile)$ tar (여러개의 파일을 하나의 파일로 묶는다.)# tar -cvf merged_file.tar /test/etc // /test/ectdml 파일 및 디렉터리를 묶는다.# tar -xvf merged_file.tar // 묶은것을 해제한다.$ time (특정 프로세스나 명령어에 사용된 시스템 자원 정보를 출력한다.)# time ls$ touch (0바이트의 빈 파일을 생성하거나, 파일 존재시 수정시간을 현재 시간으로 변경한다.)$ tr (특정 문자를 다른 문자로 변경할 때 사용. 대부분 재지정 시 활용)# tr \"a-z\" \"A-Z\" < tr.test // 소문자를 대문자로 변경# tr -d \"_\" < tr.test // 모든 '_' 제거$ traceroute (네트워크 경로를 확인하기 위해 패킷이 거쳐가는 경로 추적. 경로중에 부하높은곳을 찾을수 있다.)$. uptime (평균 시스템 부하 정보 출력)$. w (로그인한 사용자 출력)$. sed (스트림 편집기를 의미하며, 택스트 처리 혹은 치환 용도로 사용된다.)$. awk (텍스트 형태의 데이터를 행과 열로 구분하여 처리하고 결과를 출력한다. 조건문 사용가능 )# awk '표현식 {액션}' 파일# awk -f [awk 명령 스크립트 파일] 파일# cat /etc/passwd | awk -F: '/^user/{print $1, $6}'# df -k | grep -v Filesystem | sed -e s/%//g | awk '$5 > 70 {print $0}' // 디스크 사용량이 70% 이상인 파일시스템 확인# grep '^Listen' /etc/httpd.conf | awk '{if($2 == 80) print \"Http Service Port is 80\"; else print Service Port is Not 80}'# cat /etc/passwd| awk -F: 'BEGIN{print \"User / Home Dir\"};/^_k/{print $1,$6};END{print \"- END -\"}' // BEGIN, END 사용# cat /etc/passwd | awk -F: '/[nologin]$/{print $1 | \"sort\"}'$ env, printenv (환경변수보기) $ set (현재 쉘에서만 사용할수 있는 지역변수 보기),$ rm (파일지우기)# pipe로 지우는 방법.. ls -al | grep -v '^d' | awk '{print $9}' | xargs rm$ ps -ef# You can add 'aux' option to show usages of CPU, MEM and process status$ file -I {{fileName}}# file 인코딩 확인# 머신, 하드웨어 타입 출력$ uname -m # 운영체제 이름 출력$ uname -s# 모든 정보 출력$ uname -a# Client url로 서버와 통신할수 있는 command line tool# proxy, cookie, header 설정 가능# 다양한 프로토콜 지원# -L 옵션의 경우, 서버에서 301,302으로 응답이 왔을경우, redirect url을 따라간다.$ curl -L www.naver.com # -o 옵션의 경우, 출력 내용을 파일로 저장한다. (파일 다운로드시에 유용)# -O 의 경우 remote file name 으로 저장한다. (파일 length 없으면 에러)$ curl -o ~/Development/test/google www.google.com# 파일이나 디렉토리의 접근 권한을 변경# +x 옵션의 경우, $ chmod +x /usr/local/bin/docker-compose# 사용자 컴퓨터의 네트워크 환경을 알려줌 : 시스템 네트워크 연결목록# 로컬과 리모트 서버 ip/호스트네임과 포트 표기# LISTENING : 접속대기상태, ESTABLISHED : 접속된 상태, SYN_SENT : 접속하기위해 패킷보냄$ netstat # list open files 로써, 열린파일목록 및 사용하는 프로세스, 디바이스정보 파일종류등을 알려줌# VFS(virtual file system)을 사용하는 유닉스, 리눅스 파일 시스템에서 사용# 다른 유사한 명령어가 linux,unix 계열 명령어가 있지만, 제각각 이라서, lsof 사용이 유리# 열린파일정보$ lsof# 특정 포트를 사용하는 프로세스 정보$ lsof -i TCP:22$ lsof -i :8080$ lsof -i :22-8080# 특정 명령어가 사용하는 포트# apache httpd 의 경우 fork 하여 여러개 프로세스 띄움$ lsof -c httpd# 현재 열려있는 포트# -n 옵션은, 네트워크 번호를 이름으로 변경하는것을 금지, lsof 더빨리 실행될수 있음# -P 옵션은, 서비스 이름대신 포트로 표시$ lsof -i -nP | grep LISTEN | awk '{print $(NF-1)\" \"$1}' | sort -u# $0 이라는 내부변수에 레코드(입력받은 각 라인)을 할당하고, 공백을 기준으로 $1 부터 데이터가 할당된다.# NR : 레코드 넘버가 저장된다.# NF : 레코드의 컬럼 사이즈, 컬럼의 개수# awkfile 에서 'tomcat'이 포함된 라인에 1번째, 3번째 컬럼을 출력한다.$ awk '/tomcat/ {print $1, $3}' awkfile# Capacity 가 50% 이하인 filesystem 출력$ df -h | awk '$5 < 50' # printf 를 사용하면, 포멧팅된 출력 이용이 가능하다.$ awk '{printf \"이름은 %-20s, 숫자는 %4d\\n\", $1\" \"$2, $3}' awkfile# -f 옵션을 사용하여, 액션과 명령어를 파일로부터 가져와 사용할수 있다.$ awk -f {{awkCommandFileName}} {{awkFile}}# -F 으로 FS(구분자)를 변경한다.# awk -F{{구분자}} '/tomcat/{print $1, $2}' awkfile$ awk -F: '/tomcat/{print $1, $2}' awkfile# https://zzsza.github.io/development/2017/12/20/linux-6/ 나머지 정리눈 여기# 리눅스 디렉토리 용량 확인# 확인전에 df로 먼저?# df 명령은 현재 마운트 된 파일시스템의 상태를 기초로하여 사용률을 보여주는것이고,# du 명령은 실제 디렉토리와 파일을 확인하고 그 크기를 보여준다.# df의 경우 deleted 된 파일의 용량까지 포함해서 보여준다. 이는 lsof로 deleted상태의 프로세스를 종료혹은 리셋시킨다.# folder 용량확인$ du -hs {{folder}}# 현재 위치에 디렉토리들 용량확인$ du -hs *# 현재 위치에 있는 폴더 및 파일중에서 용량 사이즈 큰것으로 정렬한것중 상위 10개만 보기$ du -hsx * | sort -rh | head -n 10# 디스크$ df# ?? $ nslookup# 재귀 삭제find . -type f -name \"build\" -exec rm -rf {} \\;find . -type d -name \"build\" -exec rm -rf {} \\;find . -type d -name \"out\" -exec rm -rf {} \\; Vi editor12345671. 입력모드, 노멀모드, 명령모드, 비주얼모드(노멀 모드에서 v. 포인터부터 드래그 효과)2. 이동 ::: 0 (노멀모드에서 맨 앞으로 포인트 이동), $ (노멀모드에서 맨뒤로 포인터 이동), G (맨 마지막 행으로 이동) 3. 삭제 ::: u (명령취소), dd,[숫자]dd (숫자 수만큼 라인 삭제)4. 복사 ::: yy, [숫자]yy (커서위치한곳부터 숫자만큼 복사), p (복사한 내용을 아래쪽에 붙이기), P (복사한 내용을 위쪽에 붙이기)5. 환경설정 1. set nu (넘버링.. 반대는 set nonu) 2. set list (특수(개행) 문자 표시.. 반대는 set nolist) Shell script syntax1231. 변수와 할당되는 값사이에 빈공간 있으면 않됨! 2. 명령결과 치환 : 변수=`명령어` 와 같이 하면, 변수에는 명령어 결과가 들어간다. 와우 1. TEST=`expr 1 + 1` 혹은 TEST6=`expr 205 + \\( 3 \\* 4 \\)` Example) 1234567891011#!/bin/bashecho -n \"숫자 A를 입력하세요:\"read VAR1echo -n \"숫자 B를 입력하세요:\"read VAR2if[ $VAR1 -eq $VAR2 ] then echo \" 숫자 A와 B는 같습니다.\" elif [ $VAR1 -ge $VAR2 ] then echo \"숫자 A는 B보다 크거나 같습니다.\" Useful composed commands12345# Kill process by PROCESS_NAME# like $ sudo kill -9 `ps -ef | grep EppClient | grep -v 'grep' | awk '{print $2}'`$ kill -9 `ps -ef | grep 'PROCESS_NAME' | awk {print $2}` $ sudo ls -al /var/lib/docker/containers/ | grep `docker ps -a | grep 'DOCKER_CONTAINER_NAME' | awk '{print $1}'` | awk '{print \"/var/lib/docker/containers/\"$9}' VI Tips1234567891011## Replace all# %s/before/after\\r/g # 위 명령어로 before 를 after(개행) 으로 처리하며 이를 /g 모두 반영한다.# 공백 모두 제거# %s/ \\+$//# ^M 문자가 엄청 포함되어 있을때, 제거하기# :e ++ff=dos# :set ff=unix# :wq","link":"/2019/04/08/shell-command-and-script/"},{"title":"Enhanced factory pattern with spring framework","text":"목표스프링 프레임워크 프로젝트에서 Bean 생성 혹은 선택을 Factory pattern으로 구현한 설계를 개선한다. OCP 에 좀더 부합하도록 코드 리펙터링을 진행하고 싶다. 클래스 안에 If, else 구문 제거 시키고 싶다. 재사용성 및 중복코드 제거 하고 싶다. 배경프로젝트를 진행하면서 특정 type으로 서로다른 구현체(Bean)를 필요하는 경우 Factory pattern 을 사용하여 다형성을 구현하였습니다. 이를 통해 다양한 타입에 따른 Bean 생성혹은 선택 로직을 팩토리 클래스 하나에 응집시켜, 관련 로직 수정시 단순히 팩토리 메소드 안에 있는 코드만 수정함으로써 어느정도 유지보수에 도움을 줄수 있었습니다. 하지만 서로 다른 성격의 type들이 추가되고, 이러한 팩토리 클래스 종류도 다양해지고 많아졌습니다. 일반적으로 해당 팩토리 클래스의 구현은 if(type.equals(“A”)) else if .. 와 같은식으로 구현되고 있기 때문에 동일 팩토리 클래스에 새로운 type 을 추가하고 싶을경우 해당 팩토리 클래스의 수정이 불가피 했습니다. 결국 OCP에 부합하지 않는 코드가 계속적으로 만들어 지고 있는중 입니다. 123456789101112131415161718192021222324252627282930313233@Componentpublic class CoffeeMakerFactoryLegacy {// @Autowired private AmericanoMakerLegacy americanoMakerLegacy;// @Autowired private CappuccinoMakerLegacy cappuccinoMakerLegacy;// @Autowired private EspressoMakerLegacy espressoMakerLegacy; @Autowired private CoffeeMakerLegacy americanoMakerLegacy; @Autowired private CoffeeMakerLegacy cappuccinoMakerLegacy; @Autowired private CoffeeMakerLegacy espressoMakerLegacy; public CoffeeMakerLegacy select(CoffeeName coffeeName) { if (CoffeeName.Americano == coffeeName) { return americanoMakerLegacy; } else if (CoffeeName.Cappuccino == coffeeName) { return cappuccinoMakerLegacy; } else if (CoffeeName.Espresso == coffeeName) { return espressoMakerLegacy; } else { throw new RuntimeException(\"Invalid CoffeeName : \" + coffeeName.name()); } }}public interface CoffeeMakerLegacy { Coffee make();}@Componentpublic class AmericanoMakerLegacy implements CoffeeMakerLegacy { @Override public Coffee make() { return new Americano(); }} 문제 해결크게 2가지 Skill 을 통해 OCP 에 부합하는 Factory pattern을 구현해 보고자 합니다. Spring framework 의 DI 자료구조중에 Map 그밖에 다양한 기본기술이 사용되지만, 핵심이 되는 기술은 위와 같습니다. 그럼 이러한 2가지 기술을 통해, 보다 OCP에 부합되는 소프트웨어를 만들어 봅시다. 123456789101112131415@Componentpublic class CoffeeMakerFactoryList { @Autowired private List coffeeMakers; /** * getChannel() 호출시, 매번 n(bean 개수)번씩 loop 순회 필요 */ public CoffeeMakerV1 select(CoffeeName coffeeName) { return coffeeMakers.stream() .filter(c -> c.key() == coffeeName) .collect(Collectors.toList()) .get(0); }} List autowired 를 통한 첫번째 방법 입니다. select() 호출시, 매번 n번의 Bean 탐색이 필요합니다. 12345678910111213141516171819202122232425262728293031323334@Componentpublic class CoffeeMakerFactoryMap { private final Map coffeeMakerMap = new HashMap(); /** * Spring beans 초기화시에 호출 **/ @Autowired private void init(List coffeeMakers) { coffeeMakers.forEach(c -> coffeeMakerMap.put(c.key(), c)); } public CoffeeMakerV1 select(CoffeeName coffeeName) { return coffeeMakerMap.get(coffeeName); }}public interface CoffeeMakerV1 { CoffeeName key(); Coffee make();}@Componentpublic class AmericanoMakerV1 implements CoffeeMakerV1 { @Override public CoffeeName key() { return CoffeeName.Americano; } @Override public Coffee make() { return new Americano(); }} Map autowired 를 통한 두번째 방법 입니다. 위와 같이 만들경우, 새로운 구현체(Bean)가 추가되더라도, 기존의 Factory 클래스의 코드 변경이 없습니다. 스프링 환경의 초기화 시점에 해당 Interface(CoffeeMakerV1) 를 구현하고 있는 bean들은 Autowired 됩니다. 결론적으로 OCP를 충족시켜 줄수 있습니다. 또한 프로젝트에 다양하게 존재한 type별 구현체 if else 구문이 모두 제거 되어 코드 복잡도를 좀더 낮출수 있게 되었습니다. 그렇지만 아직 한가지 아쉬운 부분은 이러한 코드 또한, 다양한 팩토리 메소드 마다 중복 존재한다는 부분입니다. 중복제거 및 재사용 관점에서 알아보겠습니다. 중복 제거 및 재사용 관점위의 아키텍쳐에서 pattern 이 존재하는것을 확인할수있습니다. 이를 하나로 통합하여, 추후에 적용해야하는 다양한 팩토리 클래스에 대해서 일괄 적용한다면, 중복코드 제거 및 재사용성을 높일수 있습니다. 이를 위해 추가적으로 2가지 컨셉을 적용해 보겠습니다. 디자인 패턴 중 Template pattern Spring framework 4.0 에서부터 제공하는 Autowiring of Generic Types 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Supported from Spring 4.0 and later */public abstract class AbstractBeanSelector { private final Map beanMap = new HashMap(); @Autowired private void init(List beans) { beans.forEach(bean -> beanMap.put(bean.key(), bean)); } public V select(K type) { return beanMap.get(type); }}public interface Key { K key();}public interface CoffeeMaker extends Key { Coffee make();}@Componentpublic class CoffeeMakerBeanSelector extends AbstractBeanSelector {}/** * 아래와 같이 CoffeeMaker 구현체인 AmericanoMaker 만 추가함으로써 확장 가능 */ @Componentpublic class AmericanoMaker implements CoffeeMaker { @Override public CoffeeName key() { return CoffeeName.Americano; } @Override public Coffee make() { return new Americano(); }}@Componentpublic class Barista { @Autowired private AbstractBeanSelector coffeeMakerBeanSelector; public Coffee make(CoffeeName coffeeName) { CoffeeMakerV2 coffeeMaker = coffeeMakerBeanSelector.select(coffeeName) .orElseThrow(() -> new RuntimeException(\"못만들어요 : \" + coffeeName)); return coffeeMaker.make(); }} 이제 Barista(최초 caller)는 단순히 AbstractBeanSelector 타입으로만 디펜던시가 존재하며, 스프링에서 coffeeMakerBeanSelector 이름의 구현체 Bean 을 autowiring 시켜 줍니다. 이를 단순히 coffeeMakerBeanSelector.select(coffeeName) 메소드를 통해 Bean을 가지고 올수 있습니다. 이를 위해 기존 클래스를 제외하고 추가 되어야 하는 클래스는 아래와 같이 CoffeeMakerBeanSelector 밖에 없습니다. 123@Componentpublic class CoffeeMakerBeanSelector extends AbstractBeanSelector {} 이제는 중복 코드가 존재 하지 않습니다. 재사용도 무척 편리합니다. 딥다이브:깊게생각해보기최종적으로 도출된 재사용성이 높은 클래스에는 혹시 이슈가 있을까요? 아니면 추가적으로 필요한 비지니스가 생길수 있을까요? 휴먼에러가 될수도 있고, 의도하였거나 하지 못한 부분이 생겨날수도 있는 부분이 있습니다. 사용하는 자료구조가 Map 이라는것에 이슈가 생길수도 있습니다. 예를들어, 비지니스에 변경및 추가가 생겨서 새로운 CoffeeMaker 구현체가 추가된다고 가정해 봅시다. 그러한 CoffeeMaker의 구현체 Key가 이미 존재하는 구현체의 Key와 겹친다면? 둘중 하나는 CoffeeMaker구현체는 Map의 Value에서 사라져 버리겠죠. 이를 개발자에게 인지시켜주거나 새로운 로직 추가 및 분기가 필요해 보입니다. 만일 Bean(ex. CoffeeMaker구현체) 마다 유니크한 Key를 가지는것이 원칙일때, 개발과정에서 동일 키를 가진 Bean이 추가됬을 경우, 서비스가 deployed 되기 전에(Spring beans initialize 시점에) 개발자에게 에러 상황을 알려줘야 합니다. 123456789101112131415161718192021222324252627282930/** * Supported from Spring 4.0 and later * Bean 이 Single Key 를 가지고 있고, key 값이 Unique 한 경우. * K:V = 1:1 */public abstract class AbstractUniqueBeanSelector { private final Map beanMap = new HashMap(); @Autowired private void init(List beans) { if (beans.isEmpty()) { throw new RuntimeException(\"Bean is not exist : \" + getClass().getSimpleName()); } for (V bean : beans) { if (beanMap.get(bean.key()) != null) { throw new RuntimeException(\"Bean's key is not unique : \" + bean.key()); } beanMap.put(bean.key(), bean); } } public Optional select(K type) { return Optional.ofNullable(beanMap.get(type)); }}public interface SingleKey { K key();} 그러나 만약 하나의 key에 2개 이상의 Bean이 존재할수 있다면, 이를 시스템적으로 지원해 주도록 해야합니다. 12345678910111213141516171819202122232425/** * !Supported from Spring 4.0 and later * Bean 이 Single Key 를 가지고 있고, 하나의 Key 값에 여러 Bean 이 존재하는경우 * K:V = 1:n 인경우 사용 */public abstract class AbstractMultipleBeanSelector { private final Map beanMap = new HashMap(); @Autowired private void init(List beans) { if (beans.isEmpty()) { throw new RuntimeException(\"Bean is not exist : \" + getClass().getSimpleName()); } for (V bean : beans) { beanMap.computeIfAbsent(bean.key(), k -> new ArrayList()) .add(bean); } } public List select(K type) { List beans = beanMap.get(type); return beans == null ? new ArrayList() : beans; }} 마지막으로 K:V 가 n:n 일경우 12345678910111213141516171819202122232425262728293031/** * !Supported from Spring 4.0 and later * Bean 이 Multiple Key 를 가지고 있고, 하나의 Key 값에 여러 Bean 이 존재하는경우 * K:V = n:n 인경우 사용 */public abstract class AbstractMultipleBeanSelectorWithMultipleKey { private final Map beanMap = new HashMap(); @Autowired private void init(List beans) { if (beans.isEmpty()) { throw new RuntimeException(\"Bean is not exist : \" + getClass().getSimpleName()); } for (V bean : beans) { for (K key : bean.keys()) { beanMap.computeIfAbsent(key, k -> new ArrayList()) .add(bean); } } } public List select(K type) { List beans = beanMap.get(type); return beans == null ? new ArrayList() : beans; }}public interface MultipleKey { List keys();} 정리 SpringFramework 안에서 OCP 및 재사용성을 높인 Enhanced Abstract Factory Pattern 을 만들어 보았습니다.","link":"/2019/06/06/spring-design-pattern-first/"},{"title":"Kafka","text":"정의 링크드인 에서 개발된 ‘분산 메시징 시스템’ 대용량 실시간 로그 처리에 특화되어 있음. TPS 높음 vs 기존 메시징 시스템 TPS 가 보다 뛰어나다. 성능이 아주 좋다. 분산 및 복제 구성을 보다 쉽게 사용할수 있다. TCP 기반의 프로토콜을 사용하여, 프로토콜에 의한 오버헤드가 감소했다. Producer 에서 batch 형태로 Publish 가능하여, TCP/IP 라운드트립 횟수를 줄일수 있다. (좀더 빠르다?!) 메시지를 메모리가 아닌 ‘파일시스템’에 저장한다. 자동으로 영속성(durability) 보장. 메시지가 누적되어도 성능 감소 영향 없음. 실시간 처리 뿐만 아니라, 주기적 batch 작업을 위한 데이터 저장용도로도 사용가능. Consumer는 pulling 방식으로 동작하여 최고의 퍼포먼스를 발휘할수 있다. 처리해야 하는 메시지에 대한 메타 정보를 Consumer가 트래킹 하고 있어서, Broker의 관리 부담이 줄어들었다. 구현기술 Pub/Sub 모델로 동작하며, Producer, Broker, Consumer로 구성되어 있다. Topic 이라는 개념으로 메시지를 관리한다. 실제 메시지는 Topic을 ‘Partition’이란 단위로 나눠서 메시지큐에 저장하고 사용된다. Partition 들은 클러스터의 각 노드에 분산 저장된다. 고가용성을 위한 복제(replication) 설정시에 복제된 Partition 도 분산 저장되며, 장애 발생시 Partition 단위로 Fail over가 수행된다. Partition 에선 Message 에게 Offset 이라는 unique 한 ID를 부여하고, 이를 식별자로 사용한다. Offset은 Partition 마다 관리됨으로, 특정 메시지를 찾을땐, ‘partition 번호 + offset 값’ 으로 찾아야 한다. Topic으로 들어온 메시지는 기본적으로 라운드로빈 방식으로 Partition에 분배된다. Replication factor 값 설정을 통해 복제 설정을 할수 있다. ex) replication factor 3으로 설정시, 똑같은 파티션이 3개의 노드에 존재하게 된다. 확장성(scale-out)과 고가용성(High availability)을 위해 Broker들이 클러스터로 동작한다. 사실은 Zookeeper 가 클러스터 관리한다?! 커밋과 오프셋 자동커밋과 수동커밋 주요개념순서사용Kafka cli 사용123456789101112131415161718192021222324252627282930313233343536373839404142434445# 선행조건# 1. https://kafka.apache.org/downloads 에서 카프카 다운로드# 2. 압축해제후 해당 디렉토리를 .bashrc 혹은 .zshrc에 전역 변수로 등록# ex) export KAFKA_HOME=~/Development/supports/kafka_2.11-2.0.0# Run Zookeeper for Kafka$KAFKA_HOME/bin/zookeeper-server-start.sh $KAFKA_HOME/config/zookeeper.properties# Run Kafka Server$KAFKA_HOME/bin/kafka-server-start.sh $KAFKA_HOME/config/server.properties# Create Kafka Topic$KAFKA_HOME/bin/kafka-topics.sh --create \\ --zookeeper localhost:2181 \\ --replication-factor 1 --partitions 13 \\ --topic my-topic# List Topics$KAFKA_HOME/bin/kafka-topics.sh --list \\ --zookeeper localhost:2181 # Run Kafka Producer Console$KAFKA_HOME/bin/kafka-console-producer.sh \\ --broker-list localhost:9092 \\ --topic my-topic# Run Kafka Consumer Console# Order is only guaranteed within a partition.$KAFKA_HOME/bin/kafka-console-consumer.sh \\ --bootstrap-server localhost:9092 \\ --topic my-topic \\ --from-beginning# Run Consumer with consumer group idkafka/bin/kafka-console-consumer.sh \\ --bootstrap-server localhost:9092 \\ --topic my-topic \\ --consumer-property group.id=mygroup # Topology of Kafka Topic Partition Ownership # to see how the Kafka topic is laid out among the Kafka brokers. # The ---describe will show partitions, ISRs:in-sync replicas, and broker partition leadership.)$KAFKA_HOME/bin/kafka-topics.sh --describe \\ --topic ap.pushtriggerevent.1 \\ --zookeeper localhost:2181 정리Computing architecture trend Loosely coupled computing architecture(Not strongly coupled) Not persistent every thing, Can be auto-scale in/out So result, Asynchronous Messaging freamwork. like kafka, akka Reference http://cloudurable.com/blog/kafka-tutorial-kafka-from-command-line/index.html https://epicdevs.com/17 https://taetaetae.github.io/2017/11/02/what-is-kafka/ https://getto215.github.io/kafka-architecture-2/ https://medium.com/@umanking/%EC%B9%B4%ED%94%84%EC%B9%B4%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0-%ED%95%98%EA%B8%B0%EC%A0%84%EC%97%90-%EB%A8%BC%EC%A0%80-data%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C-%EC%9D%B4%EC%95%BC%EA%B8%B0%ED%95%B4%EB%B3%B4%EC%9E%90-d2e3ca2f3c2 https://www.popit.kr/kafka-%EC%9A%B4%EC%98%81%EC%9E%90%EA%B0%80-%EB%A7%90%ED%95%98%EB%8A%94-%EC%B2%98%EC%9D%8C-%EC%A0%91%ED%95%98%EB%8A%94-kafka/ https://coding-start.tistory.com/133","link":"/2019/08/06/kafka/"},{"title":"Apache Airflow","text":"정의 Airflow is a platform to programmaticaly author, schedule and monitor workflows or data pipelines Workflow is a sequence of tasks started on a schedule or triggered by an event A traditional ETL Approach Writing a script to pull data from database and send it to HDFS to process. Schedule the script as a cronjob. Problem Failures retry if failure happens (how many times? how often?) Monitoring success or failure status, how log does the process runs? Dependencies Data dependencies : upstream data is missing. Execution dependencies : job 2 runs after job 1 is finished. Scalability there is no centralized scheduler between different cron machines. Deployment deploy new changes constantly Process historic data backfill/rerun historical data A workflow (data-pipeline) management system developed by Airbnb A framework to define tasks & dependencies in python Executing, scheduling, distributing tasks accross worker nodes. View of present and past runs, logging feature Extensible through plugins Nice UI, possibility to define REST interface Interact well with database Airflow DAG A workflow as a Directed Acyclic Graph (DAG) with multiple tasks which can be executed independently Airflow DAGs are composed of Tasks What makes Airflow great? Can handle upstream/downstream dependencies gracefully (Example : upstream missing tables) Easy to reprocess historical jobs by date, or re-run for specific intervals Jobs can pass parameters to other jobs downstream Handle errors and failures gracefully. Automatically retry when a task fails. Ease of deployment of workflow changes (continuous integration) Integrations with a log of infrastructure (Hive, Presto, Druid, AWS, Google cloud, etc) Data sensors to trigger a DAG when data arrives Job testing through airflow itself Accessibility of log files and other meta-data through the web GUI Implement trigger rules for tasks Monitoring all jobs status in real time + Email alerts Community support Airflow applications Data warehousing : cleanse, organize, data quality check, and publish/stream data into our growing data warehouse Machine Learning : automate machine learning workflows Growth analytics : compute metrics around guest and host engagement as well as growth accounting Experimentation : compute A/B testing experimentation frameworks logic and aggregates Email targeting : apply rules to target and engage users through email campaigns Sessionization : compute clickstream and time spent datasets Search: compute search ranking related metrics Data infrastructure maintenance : database scrapes, floder cleanup, applying data retention policies, … Running Airflow using Docker What is Docker ? Docker is an open platform for developing, shipping, and running applications Docker provides the ability to package and run an application in a loosely isolated environment called a container. The isolation and security allow you to run many containers simultaneously on a given host, regardless of its operating system: Mac, Windows, PC, cloud, data center, … Containers are lightweight because they don’t need the extra load of a hypervisor, but run directly within the host machine’s kernel. This means you can run more containers on a given hardware combination than if you were using virtual machines. Benefits of using Docker Docker is freeing us from the task of manaing, maintening all of the Airflow dependencies, and deployment. Easy to share and deploy different versions and environments. Keep track through Github tags and releases. Ease of deployment from testing to production environment. Best tutorial https://github.com/tuanavu/airflow-tutorial Writing your first workflow Steps to write an Airflow DAG A DAG file, which is basically just a Python script, is a configuration file specifying the DAG’s structure as code. There are only 5 steps you need to remember to write an Airflow DAG or workflow Step 1 : Importing modules Step 2 : Define default Arguments Step 3 : Instanticate a DAG Step 4 : Tasks Step 5 : Setting up Dependencies Set the dependencies or the order in which the tasks should be executed in. Here’s a few ways you can define dependencies between them: downstream example : t1 >> t2 list of tasks can also be set as : t1 >> [t2, t3] Recap Basically a DAG is just a Python file, which is used to organize tasks and set their execution context. DAGs do not perform any actual computation. Instead, tasks are the elements of Airflow that actually “do the work” we want performed. And it is your job to write the configuration and orgaize the tasks in specific orders to create a complete data pipeline. Airflow concept We will learn about Airflow’s key concept Overview Airflow is a workflow management system which is used to programmatically author, schedule and monitor workflows DAGs Workflows are called DAGs (Directed Acyclic Graph). A DAG is a collection of alll the tasks you want to run, organized in a way that reflects their relationships and dependencies. Understand Directed Acyclic Graph To understand what is a Directed Acyclic Graph? First, we need to understand the graph data structure. This is a very special data structure in computer science. A Graph has 2 main parts: The vertices (nodes) where the data is stored The edges (connections) which connect the nodes Graphs are used to solve many real-life problems because they are used to represent networks. For example: social networks, system of roads, airline flights from city to city, how the Internet is conneted, etc To represent direction in a graph Undirected graph: The relationship exists in both directions, the edge has no direction. Example : If Mary was a friend of Francis, Francis would likewise be a friend of Mary. Directed graph (digraph): Direction matters, since the edges in a graph are all one-way An example graph: the course requirements for a computer science major. The class prerequisites graph is clearly a digraph since you must take some classes before others. Acyclic graph: a graph has no cycles. Cyclic graph: a graph has cycles. A cycle in a directed graph is a path that starts and ends at the same node. It has loop. DAGs Summary Directed Acyclic Graph is a graph that has no cycles and data in each node flows forward in only one direction. It is useful to represent a complex data flows using a graph. Each node in the graph is a task The edges represent dependencies amongst tasks. These graphs are called computation graphs or data flow graphs and it transform the data as it flow through the graph and enable very complex numberic computations. Given that data only needs to be computed once on a given task and the computation then carries forward, the graph is directed and acyclic. This is why Airflow jobs are commonly referred to as “DAGs” (Directed Acyclic Graphs) Beside Airflow, there are other cutting edge big data/data science frameworks is bulit using graph data structure. Tensorflow - An open source machine learning framework TensorFlow uses a dataflow graphe to represent your computation in terms of the dependencies between individual operations. Operators, and Tasks DAGs do not perform any actual computation. Instead, Operators determine what actually gets done. Task: once an operator is instantiated, it is referred to as a “task”. An operator describes a single task in a workflow. Instantiating a task requires providing a unique task_id and DAG container A DAG is a container that is used to organize tasks and set their execution context. Operators categories Typically, Operators are classified inot three categories: Sensors a certain type of operator that will keep running until a certain critera is met. Example include waiting for a certain time, external file, or upstream data source. HdfsSensor: Waits for a file or floder to ladn in HDFS NamedHivePartitionSensor: check whether the most recent partition of a Hive table is available for downstream processing Operators triggers a certain action (e.g. run a bash command, execute a python funtion, or exxecute a Hive query, etc) BashOperator: executes a bash command PythonOperator: calls an arbitrary Python function HiveOpertor: executes hql code or hive script in a specific Hive databases. BigQueryOperator: executes Google BigQuery SQL queries in a specific BigQuery database Transfers moves data from one location to another. MySqlToHiveTransfer: Moves data from MySql to Hive S3toRedshiftTransfer: load files from s3 to Redshift Working with Operators Airflow provides prebuilt operators for many common tasks. There are more operators being added by the community. You can just go to the Airflow official Github repo, specifically in the airflow / contrib / directory to look for the community added operators All operators are derived from BaseOperator and acquire much functionality throgh inheritance. Contributors can extend BaseOperator class to create custom operators as they see fit. Go to Github : apache / incubator-airflow / airflow / contrib / operators Defining Task Dependencies After defining a DAG, and instantiate all the tasks, you can then set the dependencies or the order in which the tasks should be executed in. Task dependencies are set using: the set_upstream and set_downstream operators. the bitshift operators < and >>","link":"/2019/07/01/apache-airflow/"},{"title":"Akka & k8s","text":"한것들Spring boot application 을 jar 로 만들기12// build.gradle에 아래 선언후 bootJar 실행 하면 jar떨어짐apply plugin: 'io.spring.dependency-management' Docker compose 로 spring boot 실행하기 Dockerfile 만들기 ADD 에서 파일 위치는 ‘Dockerfile 위치를 기준으로 해야함!’ 1234FROM openjdk:8-jdk-alpineADD /build/libs/springbootapp-1.0-SNAPSHOT.jar app.jarENV JAVA_OPTS=\"\"EXPOSE 8080 Docker image Build & Run 123$ docker images$ docker build -t bootapp:0.1$ docker run -p 8080:8080 bootapp:0.1 docker-compose.yml run : docker-compose up -d 1234567app: image: bootapp:0.1 ports: - 8080:8080 command: java -jar /app.jar >> ~/shared/logs/app.out 2>&1 volumes: - ~/shared/logs:~/shared/logs 참고 https://medium.com/@sairamkrish/docker-for-spring-boot-gradle-java-micro-service-done-the-right-way-2f46231dbc06 springboot + akka : http://wiki.webnori.com/display/AKKA/Spring+Boot+With+AKKA Clustering Akka in Kubernetes with Statefulset and Deployment https://medium.com/google-cloud/clustering-akka-in-kubernetes-with-statefulset-and-deployment-459c0e05f2ea Akka Cluster On Kubernetes http://charithe.github.io/akka-cluster-on-kubernetes.html","link":"/2019/07/07/akka-k8s/"},{"title":"Python's infra","text":"Class 인스턴스라는 말은 특정 객체 (a)가 어떤 클래스(A) 의 객체인지를 관계 위주로 설명할때 사용 ‘a는 인스턴스’ 모다는 ‘a는 객체’라는 표현이 어울리며, ‘a 는 A의 객체’ 보다는 ‘a는 A의 인스턴스’라는 표현이 어울린다. type(a) 는 a객체가 어떤 타입인지 return 한다. id(a) 는 a객체의 주소를 return 한다. pass 는 아무것도 사용하지 않는 문법으로, 임시로 코드를 작성할때 주로 사용된다. Constructor & Method 아래와 같이 선언 1234567class SomeParent: def __init__(self, first, second): self.first = first self.second = second def setData(self, first, second): self.first = first self.second = second 파이썬에서는 메서드의 첫번째 매개변수로 ‘self’를 사용한다. 객체를 호출할때 호출객체 자신이 전달되기 때문이다. Inheritance class SomeChild(SomeParent): classVariable = \"hello\" def pow(self): return self.first ** self.second 1234567891011 - Method overriding 도 가능하다. - classVariable 의 경우 클래스 변수이다.- Lambda - ```python >>> add = lambda a,b: a+b >>> result = add(3,4) >>> print(result) 위와 같이 람다를 사용할수 있다. Module Library. 함수나 변수 또는 클래스를 모아놓은 파일. 사용용도를 기준으로 파일을 나누어, 필요할때 해당 코드를 Import 하여 사용하기 위한 기준? 단위 포함하려는 파일이 같은 디렉토리에 있어야 한다. import ‘moduleName’ 으로 사용한다. ‘.py’는 입력하지 않아도 된다. 함수를 파일명 없이 바로 사용하고 싶다면, ‘from 모듈이름 import 모듈함수, 모듈함수, …’ 와 같이 사용할수 있다. ‘from 모듈이름 import *’ 은 ‘모듈이름’ 에 포함된 모든 함수를 사용한다는 뜻 # __name__ 변수는 파이썬이 내부적으로 사용하는 변수 이름이다. '특정.py'을 직접 실행할 경우, 해당 특정.py 내부의 __name__ 변수에는 __main__ 값이 저장된다. 하지만 파이썬 셸이나 다른 파이썬 모듈에서 import 특정 일경우, __name__ 안에는 __특정__ 이 저장되어 있다. if __name__ == \"__main__\": print (\"Hello\") 123456789101112131415- 모듈이 있는 디렉토리로 이동하지 않고 아래의 방법을 사용하여 어디서든 모듈을 불러와 사용할두 있다. - ```python $ python >>> import sys >>> sys.path >>> sys.path.append(\"/User/crayon/..\") # 혹은 $ set PYTHONPATH=/User/crayon $ python >>> import someParent >>> ~~ Package dot(.) 를 사용하여 파이썬 모듈을 계층적(디렉토리 구조)으로 관리할수 있게 해준다. 파이썬 패키지는 디렉토리와 파이썬 모듈로 이뤄져 있다. # 패키지 않의 함수 실행 방법 # 1. >>> import game.sound.echo >>> game.sound.echo.echo_test() # 2. >>> from game.sound import echo >>> echo.echo_test() # 3. >>> from game.sound.echo import echo_test >>> echo_test() # 4. 아래와 같이 사용하려면, 특정 위치의 __init__.py에 아래와 같이 선언되어야 한다. # /User/crayon/game/sound/__init__.py # __all__ = ['echo'] >>> from game.sound import * >>> echo.echo_test() 123456789101112131415161718192021222324252627282930- relative 패키지 - . 혹은 .. 으로 선언하는거 같다.### PyPI- Python Package Index의 줄임말로 파이썬 패키지 저장소### pip, pip3- Python package management system. 파이썬으로 작성된 패키지 라이브러리를 관리해 주는 시스템- python 3.4 이후에는 기본적으로 포함되어 있음- pip list 를 통해 현재 local에 설치된 파이썬 패키지 목록을 확인할수 있음- 아래를 통해 pip 를 업데이트 할수 있다.- ```bash # pip update 하기 $ pip install --upgrade pip # python 패키지 설치하기 $ pip install numpy # 특정버전 설치 $ pip install numpy == 1.0.0 # 패키지 버전 업그레이드 $ pip install --upgrade numpy # python 패키지 제거하기 $ pip uninstall numpy Virtaul env virtualenv is a tool to create isolated Python environments. pyenv, pyenv-virtualenv setting 12345678910111213141516171819202122232425$ brew install pyenv$ brew install pyenv-virtualenv$ brew install readline xz################################## write one .zshrc ##################################export PYENV_ROOT=$HOME/.pyenvif which pyenv > /dev/null; then eval \"$(pyenv init -)\"; fiif which pyenv-virtualenv-init > /dev/null; then eval \"$(pyenv virtualenv-init -)\"; fi######################################################################################$ pyenv install --list$ pyenv install 3.7.4$ pyenv uninstall 3.7.4$ pyenv global 3.7.4$ pyenv versions$ pyenv local$ pyenv which python$ pyenv virtualenv 3.7.4 sample-env## Apply env on directory$ cd some_dicrector$ pyenv local sample-env$ pyenv local$ pip list 참고 https://book.coalastudy.com/python-basic/ https://wikidocs.net/29","link":"/2019/07/11/python-infra/"},{"title":"AWS X-ray","text":"AWS X-Ray 란? Application이 처리하는 요청에 대한 데이터를 수집하는 서비스 데이터 뷰잉, 필터링 하여 서비스 이슈파악 모니터링 및 최적화를 위한 좋은 인사이트가 될수 있다. 모든 요청 응답 트레이싱. AWS 리소스, 마이크로서비스, 데이터베이스, HTTP API 등 제공되는 X-Ray SDK 활용 인터셉터 클라이언트 핸들러 HTTP 클라이언트 사용사례시작하기개념참고 https://docs.aws.amazon.com/ko_kr/xray/latest/devguide/aws-xray.html 쿠팡내부 세션:Serverless application debug deep dive (X-ray) 현륜식 , aws 솔류션 아키텍트,SA 전통 디버깅. 방식 > 로그보면서.. xray : 세그먼트로 비교 구성 : 내부서비스에 데몬(버퍼링)띄워서 xray api 호출 코드삽입 서비스맵 : 처음보는 화면 그래프를 보면서 병목 확인, 오류상황 손쉽게 확인 엣지선택하면, 히스토그램 확인할수 있음 트레이스리스트 로도 확인할수 있음 트레이스 : 세그먼트 하위세그먼트 필터 할수 있음 클라우드 메트릭을 사요할수 있음 api 관련 트레이스 단위로 데이터를 가지고 올수 있음 비용 프리티어 10만건 저장 100만건 스캔 검색 (컨디션으로 검색 안됨?) 추가 비용 100 만건당 5달러 데모 람다 함수 액티브 추적 활성화 : IAM 자동 추가됨 람다 콜드스타트 : 클라우드 와치를 통해 주기적 핑때리기.. 웜상태를 유지하기 위해.. api gateway > 람다(get news) 관련해서 서비스 반영하려고 하는데 원시 데이터텝에 개인정보 포함되어 있어서(누구나 접근하고 볼수 있음) 보안검토가 통과되지 않음.. 그래서 AWS 쪽에서는 feature 로 등록한 상태 X ray 사용위해 람다 제외하고 무조건 데몬을 띄워야함. 내부 세션 정리 Akka 와 같은 분산처리 클러스터링 베이스 서비스의 경우에 사용사례가 있는지? 참고하면 좋은 것들이 있는지 추천 부탁.","link":"/2019/07/01/aws-xray/"},{"title":"future & java","text":"Future vs CompleteableFutureFuture java7 에서 제공하는 인터페이스 비동기 프로세스 수행할수 있게 해줌 비동기 프로세스 종료확인하는 isDone(), 타임아웃 제공하고 결과 출력하는 get() 메소드 제공 간단하기는 하나 제공되는 기능이 별로 없음 CompeteableFuture java8 에서 제공하는 클래스 Future 구현?! 클래스 간에 여러 의존성에 대한 관리를 쉽게 할수 있음 Stream API 나 Optional 와 같은 람다 표현식과 파이프라인을 사용하여 비동기 작업을 조합할수 있다. 참고 https://doohyun.tistory.com/52 [아직안봄] https://medium.com/@chanhyeonglee/completable-future-%EA%B0%80%EC%9D%B4%EB%93%9C-%ED%8C%8C%ED%8A%B82-eb82768f095d","link":"/2019/07/11/java/"},{"title":"Gradle!","text":"Dependency configurations api vs implemetation https://medium.com/mindorks/implementation-vs-api-in-gradle-3-0-494c817a6fa https://developer.android.com/studio/build/gradle-plugin-3-0-0-migration.html?hl=ko api : 특정 모듈에서 변경이 발생하였을때, 변경 발생 모듈로 부터 연관된 하이라키의 가장 마지막 모듈까지 모두 빌드 implemetation : 하이라키에서 direct로 연관되어 있는 모듈만 리빌드 위 2개를 통해 빌드 및 접근 제한도 할수 잇는것 같음! 테스트 해보기 compileOnly runtimeOnly annotationProcessor Comands123./gradlew app:dependencies./gradlew app:dependencies --dependency modulename./gradlew app:dependencies --configuration compile","link":"/2019/10/30/gradle/"},{"title":"Docker","text":"What is Docker?Introduction 쉽게 배포 패키징, 대규모 환경에서 배포, 빠르고 심플하게 작업절차를 구성 원자적(automic)이면서 쉽게 쓰고 버릴 수 있는 컨테이너 개념 모든 상태가 직접 배포 결과물에 포함. 수정 불가능한 상태 > 애플리케이션 확장에 용이, 더 안정적으로 동작 장점 단일 파일인 Docker image를 통해 소프트웨어 패키징을 간소화 OS 파일 시스템을 하나의 표준화된 이미지 포맷으로 통합 모든 시스템과 모든 환경에 대해 정확히 동일한 결과물로 테스트하고 배포하는 데 사용 자원 낭비 없이 하드웨어로부터 소프트웨어 애플리케이션을 추상화 VM들을 관리하는 하이퍼바이저와 각 VM들이 실행 중인 커널은 하드웨어 시스템 자원의 일부를 점유 컨테이너는 리눅스 커널과 직접 통신하는 또다른 프로세스에 불과 단점 컨테이너는 호스트와 동일한 커널을 공유한다. 컨테이너 실행상태를 관리 하지는 않는다. 배포과정을 완전히 자동화 시켜 주지는 않는다. 내부적으로 클러스터 개념이 없다. Preview 절차단순화 개발자와 운영자 사이에 많은 프로세스들을 간소화 시켜 준다. 역할 분리와 의존성의 캡슐화를 제공 아키텍쳐 클라이언트/서버/레지스트리 모델 컨테이너 네트워킹 각각의 도커 컨테이너가 private 네트워크의 호스트 처럼 동작 도커 워크플로 리비전 제어 파일 시스템 계층 이미지태그 빌드 테스팅 패키징 배포 Client, Images, ContainersContainers 컨테이너는 호스트 시스템의 커널을 공유하며 (선택에 의해) 다른 컨테이너로부터 독립적이고 완비된 실행환경 전체 OS 환경이 필요하지 않음 커널공유 : 독립적인 작업과 하위의 실제 하드웨어 사이에 간접적인 계층이 하나 줄어든다. 그러나! 하부의 커널과 호환되는 프로세스만 실행될수 있다! Command Tools1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950$ docker version$ docker info$ docker images$ docker inspect {{containerId|containerName}}$ docker -it {{containerId|containerName}}# $ nsenter$ docker volume ls$ docker volume inspect {{volumeId}}# 컨테이너 접근 어려울때 아래로 확인 가능하다.$ sudo ls -al /var/lib/docker/containers/{{containerFullId}}$ docker logs {{containerId|containerName}} # docker logs -f {{containerId}}$ docker stats {{containerId}} # docker stats# 인증 먼저 해야함..$ curl -s http://localhost:2375/v1/containers/{{containerId}}/stats$ curl -s http://localhost:2375/v1/containers/{{containerId}}/stats | head -1 | python -m json.tool$ docker events # --since 혹은 --until 옵션으로 추가 제어 가능#### cAdvisor 라고, 구글 사내에서 쓰는 그래프용 모니터링 툴을 docker로 띄울수도 있다. 참고$ docker top {{containerId}}$ docker history {{imageId}}$ sudo docker diff {{containerId}}# 도커컨테이너 내부로 들어가기$ docker exec -it {{container_id | container_name}} /bin/bash# 도커 실행 관련# docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARGS...]# 우분투 실행# -t 혹은 (--tag) $ docker run -d -t ubuntu /bin/bash$ docker build -t {{tagname1}}/{{tabname2}} .$ docker login && docker push {{tagName1}}/{{tabName2}}$ docker rm {{containerId}}$ docker rmi {{imageId}},{{imageId}}, ...# 도커 이미지 다운로드# docker pull [OPTIONS] NAME[:TAG|@DIGEST]# tag 지정하지 않으면 최신버전으로 다운로드$ docker pull mysql# 레디스 실행# -d (백그라운드로), -p (로컬포트 4321를 도커 컨테이너 6379에 연결)$ docker run -d -p 4321:6379 redis# 도커 컨테이너 중지$ docker stop {{docker_container_id}}# 중지된 컨테이너 일괄삭제$ docker rm -v $(docker ps -a -q -f status=exited)# 컨테이너 볼륨 마운트$ docker run -d -p 3306:3306 \\ -e MYSQL_ALLOW_EMPTY_PASSWORD=true \\ --name mysql -v /my/own/dir:/var/lib/mysql mysql:5.7 Productionize, Debuging flowTools 오케스트레이션 분산 스케줄러(Distributed scheduler) :: 쿠버네티스 참고 다중 서버 노드를 단일 컴퓨터로 묶어주는 수단. 메소스와 같은 도구들은 개별 서버들과 전체 데이터 센터를 거대한 자원 풀로 추상화 하여 컨테이너 기반 작업을 수행. DeploymentEnhancedment 컨테이너를 구성하는 매커니즘 cgroup : 자원제한 메모리 스왑 CPU 등의 한도를 제어하는데 사용 작업들과 그 미래의 자식들을 포함하여 특화된 종작과 연관된 그룹들로 계층화 하기 위해서 통합/분할하는 매커니즘 namespace : 프로세스 구분, 시스템과 독립된 시점을 제공 single global resource를 컨테이너에 속한 single global resource 로 보이게 만들어 준다. 마운트, UTS, IPC, PID, 네트워크, 사용자 네임스페이스 파일 시스템, 네트워크 인터페이스, 디스크, 등등 SE리눅스/앱아머 : 강한 보안 고립화 제공 Core conceptdocker-compose 사용하기12345# docker-compose 설치$ curl -L \"https://github.com/docker/compose/releases/download/1.9.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose$ chmod +x /usr/local/bin/docker-compose# test 해보기$ docker-compose version docker-compose.yml123456789101112# yaml 파일app: image: {{image-name | image-url}} ports: - 10001:10001 - 11619:11619 environment: - JVM_OPTIONS=-Xms4g -Xmx25g -XX:+UseG1GC - SPRING_PROFILE=production - CMDB_OPTS=-Dcmdb.role={{role}} -Dfile.encoding=UTF-8 volumes: - /local/dir/logs:/container/dir/logs docker options 1http://pyrasis.com/book/DockerForTheReallyImpatient/Chapter20/28 여기에 잘설명 참고docker lifeCycle 관련 : https://medium.com/@nagarwal/lifecycle-of-docker-container-d2da9f85959 Docker(container)의 작동 원리: namespaces and cgroups : https://tech.ssut.me/what-even-is-a-container/","link":"/2019/08/25/docker/"},{"title":"ML : Machine Learning","text":"구글 머신러닝소개머신러닝의 실용적 가치 이해 머신러닝의 원리 이해 Reduce time programming Customize and scale products Complete seemingly “unprogrammable” tasks etc 철학적인 이유 : 논리학에서 자연과학으로 초점이 바뀜 머신러닝 문제로 표현하기프레이밍기본적인 머신러닝 용어 알아보기 다양한 머신러닝 용도 확인 라벨 예측하는 항목(선형 회귀의 y변수) 밀의 향후 가격, 사진에 표시되는 동물의 종류 등등.. 특성 입력변수(선형 회귀의 x변수) 수백만개의 특성을 사용할수 있다. 스팸감지 예에서 이메일 텍스트의 단어 보낸느 사람의 주소 이메일이 전송된 시간 ‘이상한 속임수 하나’ 라는 구문이 포함된 이메일 모델 feature 와 label 간의 관계 정의 # {features, ?} : (x, ?) 학습이란, 모델을 만들거나 배우는 것을 의미 즉 라벨이 있는 예를 모델에 보여주고, 모델이 특성과 라벨의 관계를 점차적으로 학습하도록 한다. 추론은 학습된 모델을 라벨이 없는 예에 적용하는 것을 의미 즉 학습된 모델을 사용하여 유용한 예측(y’)을 해낸다. 회귀와 분류 회귀모델 연속적인 값을 예측 캘리포니아의 주택가격 사용자가 이 광고를 클릭할 확율 분류모델 불연속적인 값을 예측 스팸 메일인지 아닌지 이미지가 강아지 혹은 고양이 혹은 햄스터인지? 선형회귀","link":"/2019/11/28/ML/"},{"title":"토비's Spring 3.1 정리","text":"토비’s Spring 3.1 정리들어가며스프링이란? 웹 어플리케이션 서버를 개발하기 위해 필요한 모델 혹은 API 및 특징등을 제공해 주는 프레임 워크이다 스프링 컨테이너 제공 어플리케이션 컨텍스트로도 불리는 스프링 컨테이너는 서블릿을 등록하여 런타임엔진을 제공한다. 라이프 사이클을 관리해 준다. IoC/DI, 서비스추상화, AOP 과 같은 모델 제공 IoC/DI는 오브젝트 생명 주기와 의존관계에 대한 모델 서비스 추상화는, 추상계층을 두어 이식성이 뛰어난, 특정 기술에 종속적이지 않은 어플리케이션을 만들수 있도록한다. 관점지향프로그래밍 ~ 기타 API Vol. 1 스프링의 이해와 원리1장 오브젝트와 의존관계서론 스프링은 객체지향 설계 측면에서, 오브젝트를 어떻게 효과적으로 설계하고 구현하고, 사용하고 개선해 나가야할지에 대해서 손쉽게 적용할수 있도록 프레임워크 형태로 제공한다. 해당 장에서는 스프링이 무엇이고 무엇을 제공하고, 오브젝트의 설계와 구현 동작원리에 대해서 설명한다. 1.1 초난감 DAO1.2 DAO 분리 분리와 확장을 고려한 설계가 필요하다 관심사의 분리(SoC : Separation of Concern) 관심이 같은 것끼리는 모으고, 관심이 다른것은 따로 분리 예제에서는 DAO 에 너무 많은 관심사를 분리하는것으로 시작 (ex. DB연결, SQL 실행, Connection 관리) 중복코드의 메소드를 추출 및 하나로 관리함으로써, 해당 관심사에 변경이 생겼을경우 하나만 고치면됨 템플릿 메소드 패턴 상속을 통해 슈퍼클래스의 기능을 확장할때 사용하는 가장 대표적인 패턴 슈퍼클래스에 기본적인 로직의 흐름을 정의하고, 추상메소드나 오버라이딩 가능한 protected 메소드 등으로 만들어 서브 클래스에서 구현하는 방법 변하지 않는 기능은 슈퍼클래스에, 자주 변경되며 확장할 기능은 서브클래스에 만든다. 선택적으로 오버라이드 할수잇는 protected 메소드를 훅(hook) 메소드라 한다. 팩토리 메소드 패턴 서브클래스에서 구체적인 오브젝트 생성 방법을 결정하는것 추상 클래스만들어 상속을 통해, 참조하고 구현하는것 해당 메소드 하나를 사용하는데에만 관심, 구현레벨에서도 그 하나의 메소드를 구현하는것에만 관심 하지만 자바는 다중상속 지원안함, 긴밀한 결합관계가 되버린다. 1.3 DAO 확장 클래스분리 및 인터페이스 도입 인터페이스는 기능만 정의햇지, 구현방법은 나타나 있지 않아서 확실한 관심사 분리의 개념을 나타낼수 있다. 하지만 결국엔 코드에 어떤 구현체를 쓸지 명시되어 있어서, 확실한 관심사 분리가 되어있지 않다. 관계설정 책임의 분리 현재 오브젝트에서 사용할 다른 오브젝트를 생성자를 통해 주입받는 식으로 개발 두 오브젝트의 의존관계를 클라이언트로 넘겨, 어떤 구현체를 써야할지에 대한 관심사를 제거하고, 단순히 자기 자신이 어떠한 일만 처리하면 될지에 대한 관심사 만을 가져갈수 있게 되었다. 결과적으로, 이러한 구현체를 바꿔야 하는 부분이 생기면, 단순히 클라이언트만 수정해 주면 된다. 개방 폐쇄 원칙(OCP, Open-Closed Principle) 클래스나 모듈은 확장에는 열려 있어야 하고 변경에는 닫혀 있어야한다. 객체지향 설계 원칙(SOLID) by 로버트 마틴 SRP(The Single Responsibility) : 단일책임원칙 OCP(The Open Closed Principle) : 개방 폐쇄 원칙 LSP(The Liskov Substitution Principle) : 리스코프 치환 원칙 ISP(The Interface Segregation Principle) : 인터페이스 분리 원칙 DIP(The Dependency Inversion Principle) : 의존관계 역전 원칙 높은 응집도와 낮은 결합도 (high coherencde and low coupling) 높은 응집도 하나의 모듈, 클래스가 하나의 책임 또는 관심사에만 집중되어 있다. 낮은 결합도 하나의 오브젝트가 변경이 일어날 때에 관계를 맺고 잇는 다른 오브젝트에게 변화를 요구하는 정도가 낮다. 즉 변화로 인한 사이드 이펙트를 적게하는것 전략패턴(Strategy Pattern) 자신의 기능 맥락(Context)에서, 필요에 따라 변경이 필요한 알고리즘 클래스를 필요에 따라 바꾸서 사용할수 있게 하는 디자인 패턴. 그러면 결국 스프링 프레임워크 또한 전략패턴으로 설계가 된것이라고 볼수도 있다. 1.4 제어의 역전(IoC) 팩토리 객체 생성방법을 결정하고, 생성하여 돌려주는 역할 ::: 마치 설계도 로써 작동하는것 같다. 오브젝트를 생성하는 쪽과 생성된 오브젝트를 사용하는 쪽의 역할과 책임을 분리해준다. 제어의 역전에 관해 제어의 역전에서는 오브젝트가 자신이 사용할 오브젝트를 스스로 선택하지도 않고 생성하지도 않는다. 이러한 모든 오브젝트에 대한 제어 권한을 위임 서블릿이 한 예 서블릿에 대한 제어 권한을 가진 컨테이너가 적절한 시점에 서블릿 클래스의 오브젝트를 만들고 그안의 메소드를 호출한다. 라이브러리를 사용하는 애플리케이션 코드는 애플리케이션 흐름을 직접 제어한다. 하지만 프레임워크는 거꾸로 애플리케이션 코드가 프레임워크에 의해 사용된다. 프레임워크가 주도하는 중에 개발자가 만든 애플리케이션 코드를 사용하는 방식! 즉 프레임워크에는 제어의 역전 개념이 적용되어 잇어야 한다! 이러한 IoC 스타일의 설계와 코드는, 깔끔하고 유연성이 증가하며 확장성이 좋아진다. 1.5 스프링의 IoC 스프링 빈 스프링 컨테이너가 생성과 관계설정, 사용 등을 제어해 주는 제어의 역전이 적용된 오브젝트 애플리케이션 컨텍스트 빈팩토리를 확장한 개념으로, 스프링빈의 제어를 담당하는 IoC 엔진이라고 보면 된다. 빈팩토리는 빈을 등록 관리만 하는 기본적 기능을 담당하고, 컨텍스트는 더 나아가 스프링 기능을 추가적으로 지원한다. 컨테이너 혹은 IoC 컨테이너 하나의 애플리케이션에는 여러개의 애플리케이션컨텍스트가 존재하고 이를 통틀어 스프링 컨테이너라 부른다. @Configuration 을 사용하기위해, AnnotaionConfigApplicatoinContext를 사용한다. 1.6 싱글톤 레지스트리와 오브젝트 스코프 애플리케이션 컨텍스트는 싱글톤 레지스트리 이다. 매번 요청당 객체를 생성하면 부하 이슈가 있기 때문에, 서블릿 클래스당 하나의 오브젝트만 만들어두고, 요청 스레드에서 하나의 오브젝트를 공유해 동시에 사용한다. 하지만 기본적인 자바 싱글턴 모델은 아래와 같은 이슈가 있다. Private 생성자를 갖고 잇기때문에 상속할수 없다. 싱글톤은 테스트하기 힘들다. 서버환경에서는 싱글톤이 하나만 만들어지는것을 보장하지 못한다. 싱글톤의 사용은 전역 상태를 만들 수 있기 때문에 발람직하지 못하다. 그래서 스프링이 직접 싱글톤 오브젝트를 관리하는 자체 서비스를 만들엇고, 그게 ‘싱글톤 레지스트리’이다. 기본적으로 싱글톤이 멀티스레드 환경에서 서비스 형태의 오브젝트로 사용되는 경우에는 상태정보를 내부에 갖고 있지 않은 무상태(stateless) 방식으로 만들어 저야 한다. 메소드 파라미터나, 메소드 안에서 생성되는 로컬 변수는 매번 새로운 값을 저장할 독립적인 공간이 만들어지기 때문에 싱글톤 이라고 해도 여러 스레드가 변수의 값을 덮어쓸 일은 없다. 스프링 빈의 스코프 종류 싱글톤 컨테이너 내에 한개의 오브젝트만 유지. 프로토타입 컨테이너에 빈을 요청할 때마다 매번 새로운 오브젝트를 만들어 준다. 요청(Request) 새로운 HTTP 요청당 오브젝트 생성 Session 새로운 세션마다 생성 1.7 의존관계 주입(DI) 스프링은 IoC에서 더 나아가 DI 를 해줌으로, 여타 다른 프레임워크와 차별점을 둔다. (UML) A –> B : A 가 B에 의존하고 있다. 즉 B의 변경은 A에 영향을 미치지만, A의 변경은 B에 영향을 미치치 않는다. (UML) A –|> B : A 는 B를 구현한다. DI를 통해 얻을수 있는 이점 기능 구현의 교환 프로파일에 따라서 서로다른 빈을 주입할수 있다. Ex) 개발디비, 운영디비 부가기능 추가 프록시 패턴으로, 한번 랩핑하여 추가 기능을 구현할수 있다. 1.8 XML을 이용한 설정 … 1.9 정리 1장에서 한것들.. 코드분리(SoC, Refectoring) 인터페이스로 두개의 오브젝트 참조관계를 정의하고 한쪽은 접근, 한쪽은 구현하도록함. (전략패턴) 개방폐쇄원칙에 따라, 자신의 책임 변경을 제외하고 불필요한 변화가 발생하지 않도록 막아줌 한쪽의 기능 변화가 다른쪽에 영향을 미치지 않게 하고(낮은 결합도), 자신의 관심사에만 집중(높은 응집성) 오브젝트 생성 및 관리를, 팩토리에 넘겼다. 그래서 그러한 관리에 책임으로 부터 자유롭게 했다.(IoC)팩토리는 전략패턴 전통적 싱글톤 패턴에서 벗어나, 스프링은 자체적으로 싱글톤 레지스트리를 통해 싱글톤 빈을 관리한다. 설계시점에는 인터페이스로 의존성을 느슨하게 만들어놓고, 런타임시에 IoC/DI 에 의해 의존성이 결정된다. 2장 테스트서론 테스트란 무엇이며, 가치와 장점, 활용전략, 스프링과의 관계. 대표적인 테스트 프레임워크 알아보기 2.1 USERDAOTEST 다시보기 다른계층과 분리하여 테스트가 된다면, 각 레이어별로 문제를 빠르게 분리해서 찾아낼수 있다. 단위테스트 개발자 스스로 빨리 피드백 받을수 있다. 수정된 코드가 기능에 영향을 줄때, 테스트를 통해 안정성을 검증받을수 있다. 2.2 USERDAOTEST 개선 Junit 프레임워크 2.3 개발자를 위한 테스팅 프레임워크 JUNIT2.4 스프링 테스트 적용2.5 학습 테스트로 배우는 스프링2.6 정리3장 템플릿3.1 다시보는 초난감 DAO 예외처리 JDBC 에서 이슈 발생시에 커넥션 리소스 릴리즈 관련 try, catch, finally 구문을 통해 리소스 반환을 잘해줘야한다. connection.close() 시에도 에러가 발생할수 있으므로, not null 시에 close에서 한번더 try catch 해준다. ResultSet 또한 반환해야 하는 리소스 중에 하나이다. 하지만 매번 위와 같이 진행햇을때, 한번이라도 close 빼먹으면 리소스 부족으로 죽을수 있다. 따라서, 위 코드를 템플릿 패턴으로 개선하자. 변경되지 않는 부분은, 커넥션 가져오는부분, 리소스 반납하는 부분이다. 변경 필요한 부분만 abstract protected 로 슈퍼클래스에서 선언하고, 하위에서 구현하면, OCP를 확실히 구현할수 있다. 하지만 상속구조를 이용하기 때문에, 서브클래스에서 PreparedStatment라는 고정적으로 return 해줘야 하기때문에 유연성이 떨어져서, 확장이 힘들어 진다. So, 전략패턴을 적용해야한다. 전략패턴은 OPC 원칙을 잘지키면서, 템플릿 메소드 패턴보다 유연하고 확장성뛰어나다. 이는 인터페이스로 서로를 의존하도록 만들엇기 때문이다. 전략패턴에서 Context가 사용하는 전략은 앞단의 Client 에서 전달한다. 이를 기반으로 Context 는 해당 전략으로 이뤄진 구현 클래스의 오브젝트를 사용한다. 결과적으로 StatementStrategy 인터페이스를 넘겨주는 것이 확장성에 좋다. (219 페이지 다시 읽어볼것… ) 226 페이지, 전략과 클라이언트의 동거 다시 한번 읽어 볼것. 내부클래스 및 등등 결과적으로 해당 샘플에서 전략적 패턴의 구조로 보자면, UserDao의 메소드가 클라이언트이고, 익명 내부 클래스가 개별전략이고, jdbcContextWithStatementStrategy()메소드는 컨텍스트 이다. 3.2 변하는 것과 변하지 않는 것3.3 JDBC 전력 패턴의 최적화3.4 컨텍스트와 DI3.5 템플릿과 콜백3.6 스프링의 JDBCTEMPLATE3.7 정리4장 예외4.1 사라진 SQLEXCEPTION4.2 예외 전환4.3 정리5장 서비스 추상화5.1 사용자 레벨 관리 기능 추가5.2 트랜잭션 서비스 추상화5.3 서비스 추상화와 단일 책임 원칙5.4 메일 서비스 추상화5.5 정리6장 AOP6.1 트랜잭션 코드의 분리6.2 고립된 단위 테스트6.3 다이내믹 프록시와 팩토리 빈6.4 스프링 프록시 팩토리 빈6.5 스프링 AOP6.6 트랜잭션 속성6.7 애노테이션 트랜잭션 속성과 포인트컷6.8 트랜잭션 지원 테스트6.9 정리7장 스프링 핵심 기술의 응용7.1 SQL과 DAO의 분리7.2 인터페이스의 분리와 자기참조 빈7.3 서비스 추상화 적용7.4 인터페이스 상속을 통한 안전한 기능확장7.5 DI를 이용해 다양한 구현 방법 적용하기7.6 스프링 3.1의 DI7.7 정리8장 스프링이란 무엇인가?8.1 스프링의 정의8.2 스프링의 목적8.3 POJO 프로그래밍8.4 스프링의 기술8.5 정리9장 스프링 프로젝트 시작하기9.1 자바 엔터프라이즈 플랫폼과 스프링 애플리케이션9.2 개발도구와 환경9.3 애플리케이션 아키텍처9.4 정리부록 A 스프링 모듈A.1 스프링 모듈의 종류와 특징A.2 스프링 모듈의 의존관계부록 B 스프링 의존 라이브러리B.1 의존 라이브러리의 종류와 특징B.2 모듈별 의존 라이브러리 의존관계Vol. 2 스프링의 기술과 선택1장 IoC 컨테이너와 DI2장 데이터 액세스 기술3장 스프링 웹 기술과 스프링 MVC4장 스프링 @MVC5장 AOP와 LTW6장 테스트 컨텍스트 프레임워크7장 스프링의 기타 기술과 효과적인 학습방법부록 A 스프링 모듈부록 B 스프링 의존 라이브러리","link":"/2018/11/06/toby-spring-summary/"},{"title":"Setting Oracle using docker","text":"Local Base Oracle 환경구축설치방법1 https://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html Oracle DB 11g Express 로 다운로드 : 비트 확인 $ uname -a Oracle Database 11g Release 2 Express Edition downloads for Linux x86 and Windows. Express Edition 법적 정책 : https://m.blog.naver.com/PostView.nhn?blogId=hanajava&logNo=220824719322&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F 방법2 docker 로 oracle 띄워서 사용하기 (도커 설치후에) 다운로드 : https://www.docker.com/products/docker-desktop 설명 : http://lhoris.tistory.com/18 $ docker pull wnameless/oracle-xe-11g $docker run -d -p 59160:22 -p 59161:1521 wnameless/oracle-xe-11g -d : 백그라운드 실행 , -p : 호스트 포스트를 도커 포트와 매핑 접근 : system / oracle (ID/PW) 로케일 이슈잇을시에 시스템 환경설정 > 언어 및 지역 > 지역 잠깐 바꾼후에 connect해보기 Todo 로컬에 system/oracle을 netpion/netpion으로 바꾸기 로컬 시스템 재부팅시에 도커 이미지(오라클) 자동 재실행 관련 ::: systemctl https://github.com/xmlangel/docker/wiki/%EB%B6%80%ED%8C%85%EC%8B%9C-%EC%8B%9C%EC%9E%91 오라클 도커 이미지 재실행시, 내부 table 데이터 초기화 관련 ::: 호스트 디렉토리 볼륨에 맵핑하기 https://github.com/wnameless/docker-oracle-xe-11g/issues/64 docker run –name oracle11g -d -p 59161:22 -p 59162:1521 -p 59163:8080 -v /oracle11g-data/:/u01/app/oracle/oradata/oracle11g-data/ -e ORACLE_ALLOW_REMOTE=true –restart=always wnameless/oracle-xe-11g 초기 sequence 존재 안한다는 에러 ? SELECT MARKETING_EMAIL_SEQUENCE.nextval from dual; 쿼리 실행필요? docker run –name oracle11g -d -p 59161:22 -p 59162:1521 -p 59163:8080 -v /oracle11g-data/:/u01/app/oracle/oradata/oracle11g-data/ -e ORACLE_ALLOW_REMOTE=true –restart=always wnameless/oracle-xe-11g ETC tablespace란 http://12bme.tistory.com/249 http://www.gurubee.net/lecture/1094","link":"/2019/11/28/setting_oracle/"},{"title":"AWS training","text":"AWS 기반 아키텍처 설계 시작모듈0 - Tech Traniner 김현도님 (기본) 교육과정 : 아키텍쳐, 개발, 운영 on promise : I형 T형 인재 AWS 아키텍쳐 설계, 예제 3티어 웹서비스 구축 하기 모듈별 진행 예정(3 tier) S3 (presentation) - > EC2(), 컨테이너, 람다 -> DB layer (module 5 ~) 기반서비스 network -> network 확장 IAM 권한제어 확장성 가용성 및 모니터링 ELB, Cloud watch 자동화 AWS CloudFormation 캐싱 Loosed coupled 하게 MSA, 서비리스 쿠버네티스 1234## 실습사이트http://aws-class.com/43319## 교재https://online.vitalsource.com/ ARN : 리소스 식별자 클라우드 소프트웨어(API : 코드) > 모든것을 코드로 한다. > 자동화 할수 있다. > 정의 프로그래밍 가능한 리소스, 동적기능, 종량과금(디펜던시 줄여야함) 장점 빠른 대응(속도 및 민첩성. MSA, CI, CD 는 결국 빠른 Infra support 를 위해) + Fail fast 서버 vs 인스턴스 인스턴스는 1회성 작업용 AWS Well Architectred Framwork : WAF 보안, 안정성, 비용 최적화, 성능효율성, 운영탁월성 죽는경우 대비해서 설계 하기 CDN : Cloud front Region service : 모든 AZ 에 들어간다. AZ service : 특정 AZ에 들어간다. S2 EBS(Block storage) : 공유 x EFS(File storage) : NFS(리눅스 기준) S3(Object storage) : 파일시스템 x (메타데이터 줄이기) 3tier : web + index server + disk server(메타 데이터를 최소화, 진짜 폴더 아님) key value data store HA, endurance 99.9(*9) : 연간 downtime 1시간 웹서비스를 구현할수 잇다! transfer acceleration 옵션 체크: Upload 빠르게 , AWS backbone 사용. 빅데이터분석 트렌드 : ETL -> ELT (S3 연동으로 많이함) mutipart upload api 제공, 분할 다운로드도 제공(byte 단위로) S3 종류 : 과금때무네. (Life cycle 로 자동적으로 migration 설정할수 잇따.) EC2 리전선택 데이터 거버넌스 : 데이터 주권, 규정에 따라. 서비스 주요 제공 국가. 레이턴시 고려 개념 shut-down / up 사설 ip : N 공용 ip : Y IS : Y EBS : N EBS optimized (스토리지 독립 네트워크 어뎁터 사용) : 속도 좋음 EC2 root 볼륨은 기본적으로 EBS 따로 만들수도 있음 user data 로 인스턴스 시작시에 셋팅 169.254~/meta-data/public-hostname 에서 메타 데이터 가져올수잇음 스팟인스턴스로 전용인스턴스, 전용 호스트 배치그룹 AZ 내에 렉을 컨트롤 cluster(같은 렉에, 높은 bandwith), spread(서로다른렉에 배포, 렉마다의 장애, 가용성을 높이기 위해), partition(파티션그룹으로 만들어서 cluster + spread사용) 데이터베이스 SQL vs NoSQL 무결성 과 성능 RDS(관리형) , DynamoDB(완전관리형:serverless) 네트워크 VPC : 사내망 분리 route53 public ~ private :: region :: VPCs IG (for public subnet) 들어오고 나갈수 잇따. create IG > subnet~ create route > add route > destination: 0.0.0.0/0, target: pub-igw NAT GW 내보낼수만 잇다. NIC EIP 안쓰면 과금 SG EC2 interface에 할당 default deny 룰 최종 결과에 따라 statefull : 들어온거 처리하면 나가는거는 처리 안해도됨. NACL subnet 에 설정 룰 순차적으로. (범용적인 룰은 밑에 선언) stateless(패킷추적x, 인바운드 아웃바운드 따로 처리해야함) site-to-site vpn connections 1https://s3.console.aws.amazon.com/s3/buckets/website-2321/?region=us-west-2&tab=properties 관리형, 비관리형 mysql ~ ARN arn:aws;s3;:A:bucketname/filename s3는 버켓의 이름이 글로벌함. 그래서 regionName,A가 생략된다. 실습내용 S3로 웹서비스 제공 bucket 생성후(public accessable)에, 속성에서 Static web service hosting 하고, index.html 을 public 으로 하면 됨 Question 동일 AZ 를 사용하는 기업 업체가 많이 있는가? 있음 AZ 개수의 기준이 무엇? 버지니아 6, 한국3.. 속도 위험성? 일본의 경우에는 천재지변 위험성때문에 있음. 그러나 버지니아 같은경우에는 사용자가 많아서","link":"/2019/12/16/aws-training/"},{"title":"Functional programming in java8","text":"목적 구현기술 및 정의, 컨셉, 패러다임 파악 관련된 다양한 정의 혹은 개념 함수형 인터페이스 하나의 추상 메소드만 가진 인터페이스 명시적으로 @FunctioalInterface 어노테이션을 선언해 놓을수 있다. 순수함수 (Fure fuction) 동일한 입력값에 대해서 항상 동일한 출력값을 리턴하는 함수. 함수의 실행이 외부의 상태에 영향을 미치지 않는 함수 멀티쓰레드 환경 및 병렬 처리에 적합하다. 1급 객체 고차함수 정의 파라미터 혹은 리턴값을 함수로 사용하는 함수 현재 상태가 아닌 다른 상태에서 함수를 재사용 할수 있는 개념 활용 혹은 이점 객체,클래스가 아닌 함수 자체로 사용되어 작고 집중되어 있고, 두개이상 결합 가능할수 있다. 커링 렉시컬 스코프 사용한 하나의 컨텍스트에서 제공한 값을 캐시해 두었다가, 나중에 다른 컨텍스트에서 사용하는 기술 클로저와 상관 관계는? 정적 메소드의 파라미터 혹은 기타 방법으로 컨텍스트 값을 캐시하는 방법보다. Function interface를 한번더 랩핑하는것이 더 효율적이다. 1Function startWithLetter = letter -> name -> name.startWith(name); 참조 투명성 ? 일반적인 장점함수형(서술형) 스타일 vs 명령형 스타일 (명령형->선언형) for + if 으로 구성된 코드를 stream + filter + map 으로 변환하면 세련되고, 간결하고, 오류 줄어들고, 효율적이고, 더욱 쉽게 최적화 성능향상, 병렬화 가능 변수의 명시적인 재할당 문제 해결가능 병렬화 쉽게 가능 직관적, 가독성이 좀더 높다. (코드가 더 간결해 진다. 왜냐면, 로우 레벨의 판단 코드가 내부로 들어가있어서..) 객체지향에서 함수지향으로 패러다임 자체가 변하는 것은 아니다! 명령형 스타일에서 서술적 스타일로 변경된것일뿐! 설계관점에서 다양한 장점을 갖을수 있다!사용 Typed Stream 을 사용하면 sum(), max(), min(), sorted(), average() 를 사용할수 있다. reduce() 123456// reduce 에 default 값을 넣어주면 결과값이 Optional 이 아닌 String 으로 returnOptional longestNameOpt = results.stream() .reduce((n1, n2) -> n1.length() >= n2.length() ? n1:n2);// String.join(\",\", results); 와 같은results.stream().collect(joining(\",\")); String, Comparator, filter.. 123456789101112131415161718192021 // 문자의 각각의 캐릭터를 가져온다. 숫자 제외 someString.chars() .filter(ch -> !Character.isDigit(ch)) // 메서드 레퍼런스를 사용할수도 있다. .mapToObj(ch -> Character.valueOf((char)ch)); // Comparator people.stream().sorted(Person::ageDifferent).reversed(); people.stream().max(Person::ageDifferent).ifPresent(~); people.stream().sorted((p1,p2) -> p1.getName().compareTo(p2.getName())); people.stream().sorted(comparing(Person::getAge).thenComparing(Person::getName)); List personList = people.stream().collect(Collectors.toList());// 아래 groupingBy() 의 파라미터를 분류함수(classifier function) 이라고 한다. Map peopleByAge = people.stream() .collect(Collectors.groupingBy(Person::getAge)); Map nameOfPeopleByAge = people.stream() .collect(groupingBy(Person::getAge, mapping(Person::getName, toList()))); Map oldesTpersonOfEachLetter = people.steram() .collect( groupingBy(p -> p.getName().charAt(0), reducing(maxBy(comparing(Person::getAge))) ); 설계 관점에서의 FP문제의 분리 람다표현식 + Strategy pattern 으로 SoC 구현하기 1234567891011// 객체의 appleFilter라는 Predicate Functional interface를 받는 고차함수를 만듦으로써 // Strategy pattern 구현가능 및 Predicate 를 합성하여 넘겨줄수도 있음public static int findSomeApples(final List apples, final Predicate appleFilter) { return apples.stream() .filter(appleFilter) .collect(Collectos.toList());}List greenApples = findSomeApples(appleList, apple -> apple.isGreen());final Predicate greenAppleFilter = a -> a.isGreen();final Predicate redAppleFilter = a -> a.isRed();List redAndGreenApples = findSomeApples(appleList, greenAppleFilter.and(redAppleFilter)); 클래스에 독립적인 비헤이비어 구현하여 다양화. 설계 유연화 의존성 인젝션과 의존성 인버전 원칙(Dependency inversion priciple)을 적용 로직을 추상화 하고, 실제 delegate 되는 동작을 생성자 인젝션으로 설정한다. 1234567891011public class Car { private final Function engine; public Car(final Function engine) { this.engine = engine; } public int getMaxSpeed() { return engine.maxSpeed(); }} 데코레이션 패턴 구현(체이닝) 12345public void setFilters(final Function... filters) { this.filters = Stream.of(filters) .reduce((filter, nextFilter) -> filter.andThan(nextFilter)) .orElse(color -> color); // 또는 orElseGet(Function::identity)} 예외처리 1234@FunctionalInterfacepublic interface UseInstance { void accept(T instance) throw X;} 리소스 처리 패턴 JVM 은 외부 리소스에 대해서 자동으로 GC를 안함 (ex. DB connection, File socket Open, 네이티브 리소스 사용) EAM(excute around method) 패턴을 사용해야함 Lock 관리나 예외처리 테스트 가능하게함 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// ARM:automatic resource management// 자바 7부터, try 블록을 사용하면, 자바 컴파일러는 자동으로 finally 블록과 close() 메소드 호출을 추가한다.// 또한 try-with-resource 사용하기 위해서는 AutoCloseable 이 구현되어 있어야함..try(final FilteWriterARM writerARM = new FileWriterARM(\"something.txt\")) { writerARM.writeStuff(\"Hello world :)\");}// 고차함수를 사용하여 좀더 나은 방향으로 구현하기public static void use(final String fileName, final UseInstance block) throws IOException { final FileWriterEAM writerEAM = new FileWriterEAM(fileName); try { block.accept(writerEAM); } finally { writerEAM.close(); }}FileWriterEAM.use(\"test.txt\", writerEAM -> { writerEAM.writeStuff(\"Hello\"); writerEAM.writeStuff(\"World\");});// 잠금관리 관련// synchronized는 상호 배제(mutual exclusion)를 제공하기 위해 사용되는 키워드// 하지만 synchronized는 메소드가 호출되는 시간을 제어하기 힘들다. deadlock, livelock이 발생할 가능성 증가// 또한 스레드 세이프한지 테스트 하기 힘듦// Java5 에서 ReentrantLock 관련 구현체에 관련되어 Lock 관련 인터페이스 문제는 개발자가 직접 locking, unlocking 설정을 해줘야함Lock lock = new ReentrantLock();pubilc void doSome() { lock.lock(); try { // do something } finally { lock.unlock(); }}// 테스트 헬퍼 적용public class TestHelper { public static Throwable assertThrows(final Class exceptionClass, final Runnable block) { try { block.run(); } catch (Throwable ex) { if (exceptionClass.isInstance(ex)) { return ex; } } fail(\"Failed to throw expected exception \"); return null; }} 이벨류에이션 지연 지연초기화 구현가능 Eager 방식은 간단하지만, Lazy 방식은 효율적이다. (eager computaion -> lazy evaluation) 12// 생성자를 Supplier 로 제공하는 방법private final Supplier makeApple = () -> new Apple(); // 또는 Apple::new Lazy evaluation 12345678910111213141516171819202122// func1() || func2() 혹은 func1() && func2() 와 같은 short-circuit-ing 을 통해 성능 향상// 메서드에 대한 모든 인수는 실행되기전에 모두 평가 되기 때문에, 이를 지연하면 성능향상에 도움이 된다.// 메소드 내부에서 boolean 값으로 쇼트서킷이 사용되는 부분을 리팩터링 해보면public boolean isAllRight(final Supplier sup1, final Supplier sup2) { return sup1.get() && sup2.get();}// Stream 의 lazy evaluation// 중간(Intermediate) operation, 종단(Terminal) operation// Intermediate operation은 실행되기 전까지 캐시해 놓는다. // 캐시 비헤이비어는 종단 operation 호출될때 실행된다.// filter, map 메소드는 본질적으로 lazy 속성을 가진다.// findFirst() 의 경우 모든 person 이 filter()가 호출되지 않고, 찾을때 까지만 filter가 적용된다.// 즉 people 에서 3번째 한국인이 있었다면, filter(3번호출), map(1번호출) 이 된다!Optional firstKoreanName = people.stream().filter(Person::isKorean).map(Person:: getName).findFirst();// infinite stream public static boolean isPrime(final int number) { return number > 1 && IntStream.rangeClosed(2, (int) Math.sqrt(number)) .nonMatch(divisor -> number % divisor == 0);} 재귀호출최적화 (TOC : Tail-Call Optimization) Trampoline call 이라고도 한다. Memoization 기술을 사용한다. 그래서 결론은12345// 우리가 해결해야하는 문제, 개발해야 하는 목표를 코드로 설명할수 있어야 하며,// 이러한 목표를 성취하기 위해서는 문제를 좀더 서술적으로 생각하고 표현할수 있어야 한다. (추상화 레벨을 올려야 한다.)// 불변성을 선호 혹은 추구 함으로써, 병렬화 시에 가변 변수를 공유할때 생기는 이슈를 해결할수 있다.// 함수형 스타일을 사용하면 가변성을 쉽게 피할수 있다. 순수함수.. :) 참고 람다의 힘","link":"/2019/12/08/java8/"}],"tags":[{"name":"oop","slug":"oop","link":"/tags/oop/"},{"name":"객체지향","slug":"객체지향","link":"/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"},{"name":"bash","slug":"bash","link":"/tags/bash/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"spring","slug":"spring","link":"/tags/spring/"},{"name":"springframework","slug":"springframework","link":"/tags/springframework/"},{"name":"designpattern","slug":"designpattern","link":"/tags/designpattern/"},{"name":"factory","slug":"factory","link":"/tags/factory/"},{"name":"kafka","slug":"kafka","link":"/tags/kafka/"},{"name":"apache","slug":"apache","link":"/tags/apache/"},{"name":"airflow","slug":"airflow","link":"/tags/airflow/"},{"name":"akka","slug":"akka","link":"/tags/akka/"},{"name":"clustering","slug":"clustering","link":"/tags/clustering/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"infra","slug":"infra","link":"/tags/infra/"},{"name":"aws","slug":"aws","link":"/tags/aws/"},{"name":"xray","slug":"xray","link":"/tags/xray/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"future","slug":"future","link":"/tags/future/"},{"name":"java8","slug":"java8","link":"/tags/java8/"},{"name":"gradle","slug":"gradle","link":"/tags/gradle/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"ml","slug":"ml","link":"/tags/ml/"},{"name":"machinelearning","slug":"machinelearning","link":"/tags/machinelearning/"},{"name":"oracle","slug":"oracle","link":"/tags/oracle/"},{"name":"traning","slug":"traning","link":"/tags/traning/"},{"name":"functionalprogramming","slug":"functionalprogramming","link":"/tags/functionalprogramming/"}],"categories":[{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"architecture","slug":"architecture","link":"/categories/architecture/"},{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"spring","slug":"spring","link":"/categories/spring/"},{"name":"db","slug":"db","link":"/categories/db/"}]}